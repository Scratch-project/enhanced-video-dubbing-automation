{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff907e1b",
   "metadata": {},
   "source": [
    "# Enhanced Video Dubbing Automation\n",
    "\n",
    "## Arabic to English/German Video Dubbing Pipeline\n",
    "\n",
    "This notebook provides a complete automated pipeline for dubbing Arabic lecture/presentation videos into English and German, optimized for Kaggle's GPU environment.\n",
    "\n",
    "### Features:\n",
    "- **Step 0**: Environment setup and model caching\n",
    "- **Step 1**: Audio extraction and noise reduction\n",
    "- **Step 2**: Transcription with speaker diarization\n",
    "- **Step 3**: Translation using Meta SeamlessM4T v2\n",
    "- **Step 4**: Voice cloning with OpenVoice v2\n",
    "- **Step 5**: Intelligent audio-video synchronization\n",
    "- **Step 6**: Subtitle generation and integration\n",
    "- **Step 7**: Quality assurance and final assembly\n",
    "- **Step 8**: Batch processing with checkpointing\n",
    "\n",
    "### Requirements:\n",
    "- Kaggle GPU environment (P100/T4/V100)\n",
    "- Video files up to 8GB each\n",
    "- Arabic source language (Egyptian dialect supported)\n",
    "- Output: English and German dubbed videos with subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c048a",
   "metadata": {},
   "source": [
    "## üìã Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're running on Kaggle and setup environment\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "print(f\"üåê Running on Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(f\"üìÅ Working directory: /kaggle/working\")\n",
    "    print(f\"üì• Input directory: /kaggle/input\")\n",
    "    \n",
    "    # Check available GPU\n",
    "    print(\"\\nüñ•Ô∏è  GPU Information:\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if line.strip():\n",
    "                    gpu_name, memory = line.split(', ')\n",
    "                    print(f\"   üöÄ {gpu_name} ({memory}MB)\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No GPU detected\")\n",
    "    except:\n",
    "        print(\"   ‚ùì GPU status unknown\")\n",
    "else:\n",
    "    print(\"üíª Running in local environment\")\n",
    "    print(\"   Note: For local use, consider using the individual Python files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages with Kaggle optimization and proper error handling\n",
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def check_and_install_package(package_spec, import_name=None):\n",
    "    \"\"\"Install package with appropriate flags for Kaggle and verify import\"\"\"\n",
    "    # Extract package name and import name\n",
    "    package_name = package_spec.split('>=')[0].split('==')[0].replace('-', '_')\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    # Special cases for package vs import name mismatches\n",
    "    import_mapping = {\n",
    "        'openai-whisper': 'whisper',\n",
    "        'opencv-python': 'cv2',\n",
    "        'pillow': 'PIL',\n",
    "        'scikit-learn': 'sklearn'\n",
    "    }\n",
    "    \n",
    "    actual_package = package_spec.split('>=')[0].split('==')[0]\n",
    "    if actual_package in import_mapping:\n",
    "        import_name = import_mapping[actual_package]\n",
    "    \n",
    "    try:\n",
    "        # First, try to import to see if already installed\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"‚úÖ {actual_package} ‚Üí {import_name} (already available)\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Install the package\n",
    "    print(f\"üì¶ Installing {actual_package}...\")\n",
    "    \n",
    "    if IS_KAGGLE:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-warn-script-location\", package_spec]\n",
    "    else:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", package_spec]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        \n",
    "        # Verify the installation worked\n",
    "        try:\n",
    "            importlib.import_module(import_name)\n",
    "            print(f\"‚úÖ Successfully installed {actual_package} ‚Üí {import_name}\")\n",
    "            return True\n",
    "        except ImportError:\n",
    "            print(f\"‚ö†Ô∏è  {actual_package} installed but import '{import_name}' failed\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {actual_package}\")\n",
    "        print(f\"   Error: {e.stderr.decode() if e.stderr else 'Unknown error'}\")\n",
    "        return False\n",
    "\n",
    "# Essential packages for the pipeline\n",
    "print(\"üì¶ Installing Essential Packages for Video Dubbing Pipeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install packages in order of dependency\n",
    "install_sequence = [\n",
    "    # Core ML packages first\n",
    "    (\"torch>=2.0.0\", \"torch\"),\n",
    "    (\"torchaudio>=2.0.0\", \"torchaudio\"),\n",
    "    (\"transformers>=4.30.0\", \"transformers\"),\n",
    "    (\"accelerate>=0.20.0\", \"accelerate\"),\n",
    "    \n",
    "    # Audio processing\n",
    "    (\"librosa>=0.10.0\", \"librosa\"),\n",
    "    (\"soundfile>=0.12.0\", \"soundfile\"),\n",
    "    (\"noisereduce>=3.0.0\", \"noisereduce\"),\n",
    "    \n",
    "    # Video processing\n",
    "    (\"moviepy>=1.0.3\", \"moviepy\"),\n",
    "    \n",
    "    # Whisper (special handling)\n",
    "    (\"openai-whisper>=20231117\", \"whisper\"),\n",
    "    \n",
    "    # System utilities\n",
    "    (\"psutil>=5.9.0\", \"psutil\"),\n",
    "    (\"tqdm>=4.65.0\", \"tqdm\"),\n",
    "    (\"numpy>=1.24.0\", \"numpy\"),\n",
    "    (\"scipy>=1.10.0\", \"scipy\")\n",
    "]\n",
    "\n",
    "# Optional packages (nice to have but not critical)\n",
    "optional_sequence = [\n",
    "    (\"speechbrain>=0.5.0\", \"speechbrain\"),\n",
    "    (\"dtw-python>=1.3.0\", \"dtw\"),\n",
    "    (\"gitpython>=3.1.0\", \"git\"),\n",
    "    (\"matplotlib>=3.7.0\", \"matplotlib\"),\n",
    "    (\"seaborn>=0.12.0\", \"seaborn\")\n",
    "]\n",
    "\n",
    "failed_essential = []\n",
    "failed_optional = []\n",
    "\n",
    "# Install essential packages\n",
    "print(\"üîß Installing Essential Packages:\")\n",
    "for package_spec, import_name in install_sequence:\n",
    "    success = check_and_install_package(package_spec, import_name)\n",
    "    if not success:\n",
    "        failed_essential.append(package_spec)\n",
    "\n",
    "print(f\"\\nüîß Installing Optional Packages:\")\n",
    "for package_spec, import_name in optional_sequence:\n",
    "    success = check_and_install_package(package_spec, import_name)\n",
    "    if not success:\n",
    "        failed_optional.append(package_spec)\n",
    "\n",
    "# Special handling for problematic packages\n",
    "if any('whisper' in pkg for pkg in failed_essential):\n",
    "    print(f\"\\nüîÑ Attempting alternative Whisper installation...\")\n",
    "    \n",
    "    # Try alternative installation methods\n",
    "    alt_commands = [\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--force-reinstall\", \"openai-whisper\"],\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"git+https://github.com/openai/whisper.git\"]\n",
    "    ]\n",
    "    \n",
    "    whisper_success = False\n",
    "    for i, cmd in enumerate(alt_commands):\n",
    "        try:\n",
    "            print(f\"   Trying method {i+1}...\")\n",
    "            subprocess.run(cmd, check=True, capture_output=True)\n",
    "            import whisper\n",
    "            print(f\"   ‚úÖ Whisper installation successful!\")\n",
    "            failed_essential = [pkg for pkg in failed_essential if 'whisper' not in pkg]\n",
    "            whisper_success = True\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not whisper_success:\n",
    "        print(f\"   ‚ùå All Whisper installation methods failed\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nüìä Installation Summary:\")\n",
    "print(f\"=\" * 40)\n",
    "total_essential = len(install_sequence)\n",
    "success_essential = total_essential - len(failed_essential)\n",
    "print(f\"‚úÖ Essential: {success_essential}/{total_essential} packages installed\")\n",
    "\n",
    "total_optional = len(optional_sequence)\n",
    "success_optional = total_optional - len(failed_optional)\n",
    "print(f\"‚ö†Ô∏è  Optional: {success_optional}/{total_optional} packages installed\")\n",
    "\n",
    "if failed_essential:\n",
    "    print(f\"\\n‚ùå Critical packages that failed:\")\n",
    "    for pkg in failed_essential:\n",
    "        print(f\"   - {pkg}\")\n",
    "    print(f\"\\nüö® The pipeline may not work correctly without these packages!\")\n",
    "else:\n",
    "    print(f\"\\nüéâ All essential packages installed successfully!\")\n",
    "    print(f\"üöÄ Ready to proceed with video dubbing pipeline!\")\n",
    "\n",
    "if failed_optional:\n",
    "    print(f\"\\n‚ö†Ô∏è  Optional packages not installed:\")\n",
    "    for pkg in failed_optional:\n",
    "        print(f\"   - {pkg}\")\n",
    "    print(f\"   (Pipeline will work but some features may be limited)\")\n",
    "\n",
    "# Test critical imports\n",
    "print(f\"\\nüß™ Testing Critical Imports:\")\n",
    "critical_tests = [\n",
    "    (\"whisper\", \"OpenAI Whisper\"),\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"transformers\", \"HuggingFace Transformers\"),\n",
    "    (\"librosa\", \"Librosa Audio\"),\n",
    "    (\"moviepy\", \"MoviePy Video\")\n",
    "]\n",
    "\n",
    "all_critical_ok = True\n",
    "for module, description in critical_tests:\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "        print(f\"   ‚úÖ {description}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   ‚ùå {description}: {e}\")\n",
    "        all_critical_ok = False\n",
    "\n",
    "if all_critical_ok:\n",
    "    print(f\"\\nüéä All critical components ready! You can proceed to the next step.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Some critical components failed. Check the errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Troubleshoot Whisper Installation (Run this if you get ModuleNotFoundError)\n",
    "print(\"üîç Whisper Installation Troubleshooting\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    import whisper\n",
    "    print(\"‚úÖ Whisper is working correctly!\")\n",
    "    \n",
    "    # Test model loading\n",
    "    print(\"üß™ Testing Whisper model loading...\")\n",
    "    try:\n",
    "        model = whisper.load_model(\"base\")\n",
    "        print(\"‚úÖ Whisper model loading successful!\")\n",
    "        del model  # Free memory\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Model loading issue: {e}\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Whisper import failed: {e}\")\n",
    "    print(\"\\nüîÑ Attempting to fix Whisper installation...\")\n",
    "    \n",
    "    # Multiple fix attempts\n",
    "    fix_commands = [\n",
    "        # Method 1: Reinstall with force\n",
    "        [sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"openai-whisper\"],\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-cache-dir\", \"openai-whisper\"],\n",
    "        \n",
    "        # Method 2: Install from git\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--upgrade\", \n",
    "         \"git+https://github.com/openai/whisper.git\"],\n",
    "        \n",
    "        # Method 3: Try specific version\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"openai-whisper==20231117\"]\n",
    "    ]\n",
    "    \n",
    "    for i, cmd_group in enumerate([fix_commands[:2], fix_commands[2:3], fix_commands[3:4]]):\n",
    "        print(f\"\\nüì¶ Trying fix method {i+1}...\")\n",
    "        try:\n",
    "            for cmd in cmd_group:\n",
    "                if \"uninstall\" in cmd:\n",
    "                    # Uninstall quietly\n",
    "                    subprocess.run(cmd, capture_output=True, check=False)\n",
    "                else:\n",
    "                    # Install with output\n",
    "                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
    "                    if result.returncode != 0 and result.stderr:\n",
    "                        print(f\"   Warning: {result.stderr.split(chr(10))[0]}\")\n",
    "            \n",
    "            # Test if it worked\n",
    "            import importlib\n",
    "            importlib.invalidate_caches()  # Clear import cache\n",
    "            import whisper\n",
    "            print(f\"   ‚úÖ Fix method {i+1} succeeded!\")\n",
    "            break\n",
    "            \n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"   ‚è±Ô∏è  Fix method {i+1} timed out, trying next method...\")\n",
    "            continue\n",
    "        except ImportError:\n",
    "            print(f\"   ‚ùå Fix method {i+1} didn't work, trying next method...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Fix method {i+1} failed: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"\\nüö® All automatic fixes failed. Manual intervention required:\")\n",
    "        print(f\"   1. Restart the notebook kernel (Runtime ‚Üí Restart Runtime)\")\n",
    "        print(f\"   2. Run: !pip install --user --force-reinstall openai-whisper\")\n",
    "        print(f\"   3. If still failing, try: !pip install --user whisper-openai\")\n",
    "        print(f\"   4. Contact support if issue persists\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\nüî¨ Final Whisper Verification:\")\n",
    "try:\n",
    "    import whisper\n",
    "    print(f\"‚úÖ Whisper successfully imported!\")\n",
    "    print(f\"   Version: {whisper.__version__ if hasattr(whisper, '__version__') else 'Unknown'}\")\n",
    "    \n",
    "    # Quick functionality test\n",
    "    try:\n",
    "        available_models = whisper.available_models()\n",
    "        print(f\"   Available models: {list(available_models)[:3]}{'...' if len(available_models) > 3 else ''}\")\n",
    "    except:\n",
    "        print(f\"   Models list not available, but import successful\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(f\"‚ùå Whisper still not working. Please restart kernel and try again.\")\n",
    "    print(f\"   Or manually run: !pip install --user --force-reinstall openai-whisper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2cbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Kaggle Environment Setup and Path Configuration\n",
    "print(\"üîß Configuring Kaggle Environment\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    # Ensure user-installed packages are in path\n",
    "    import site\n",
    "    import sys\n",
    "    \n",
    "    # Add user site-packages to Python path\n",
    "    user_site = site.getusersitepackages()\n",
    "    if user_site not in sys.path:\n",
    "        sys.path.insert(0, user_site)\n",
    "        print(f\"‚úÖ Added user site-packages to path: {user_site}\")\n",
    "    \n",
    "    # Also add common Kaggle user install locations\n",
    "    common_paths = [\n",
    "        \"/root/.local/lib/python3.10/site-packages\",\n",
    "        \"/home/.local/lib/python3.10/site-packages\",\n",
    "        \"/opt/conda/lib/python3.10/site-packages\"\n",
    "    ]\n",
    "    \n",
    "    for path in common_paths:\n",
    "        if os.path.exists(path) and path not in sys.path:\n",
    "            sys.path.insert(0, path)\n",
    "            print(f\"‚úÖ Added path: {path}\")\n",
    "    \n",
    "    # Refresh importlib cache\n",
    "    import importlib\n",
    "    importlib.invalidate_caches()\n",
    "    \n",
    "    # Set environment variables for better package detection\n",
    "    os.environ['PYTHONPATH'] = ':'.join(sys.path)\n",
    "    \n",
    "    print(f\"üîç Current Python paths:\")\n",
    "    for i, path in enumerate(sys.path[:5]):  # Show first 5 paths\n",
    "        print(f\"   {i+1}. {path}\")\n",
    "    if len(sys.path) > 5:\n",
    "        print(f\"   ... and {len(sys.path)-5} more paths\")\n",
    "\n",
    "else:\n",
    "    print(\"üíª Local environment - no Kaggle-specific setup needed\")\n",
    "\n",
    "# Memory and GPU setup\n",
    "print(f\"\\nüñ•Ô∏è  GPU and Memory Configuration:\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"‚úÖ GPU Available: {device_name}\")\n",
    "        print(f\"   Device count: {device_count}\")\n",
    "        print(f\"   Current device: {current_device}\")\n",
    "        \n",
    "        # Clear any existing GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Get memory info\n",
    "        memory_allocated = torch.cuda.memory_allocated(current_device) / 1024**3\n",
    "        memory_reserved = torch.cuda.memory_reserved(current_device) / 1024**3\n",
    "        \n",
    "        print(f\"   Memory allocated: {memory_allocated:.2f} GB\")\n",
    "        print(f\"   Memory reserved: {memory_reserved:.2f} GB\")\n",
    "        \n",
    "        # Set memory fraction to prevent OOM\n",
    "        if not hasattr(torch.cuda, '_initialized') or not torch.cuda._initialized:\n",
    "            torch.cuda.set_per_process_memory_fraction(0.9)  # Use 90% of GPU memory\n",
    "            print(f\"   Set memory fraction to 90%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No GPU available - will use CPU (much slower)\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not available\")\n",
    "\n",
    "print(f\"\\nüéØ Environment ready for video dubbing pipeline!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cea4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project files in working directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory\n",
    "if IS_KAGGLE:\n",
    "    os.chdir('/kaggle/working')\n",
    "else:\n",
    "    # Create local working directory\n",
    "    Path('./working').mkdir(exist_ok=True)\n",
    "    os.chdir('./working')\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Create necessary directories\n",
    "directories = ['models', 'temp', 'output', 'logs', 'checkpoints', 'scripts']\n",
    "\n",
    "for directory in directories:\n",
    "    Path(directory).mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Created directory: {directory}/\")\n",
    "\n",
    "print(\"\\n‚úÖ Directory structure ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4074c",
   "metadata": {},
   "source": [
    "## üöÄ Initialize Dubbing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the main configuration file\n",
    "config_code = '''\n",
    "\"\"\"Enhanced Video Dubbing Configuration\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, local_mode=False):\n",
    "        self.local_mode = local_mode\n",
    "        self.setup_directories()\n",
    "    \n",
    "    def setup_directories(self):\n",
    "        if self.local_mode or not os.path.exists(\"/kaggle\"):\n",
    "            self.WORKING_DIR = Path(\"./working\")\n",
    "            self.INPUT_DIR = Path(\"./input\")\n",
    "        else:\n",
    "            self.WORKING_DIR = Path(\"/kaggle/working\")\n",
    "            self.INPUT_DIR = Path(\"/kaggle/input\")\n",
    "        \n",
    "        self.MODELS_DIR = self.WORKING_DIR / \"models\"\n",
    "        self.TEMP_DIR = self.WORKING_DIR / \"temp\"\n",
    "        self.OUTPUT_DIR = self.WORKING_DIR / \"output\"\n",
    "        self.LOGS_DIR = self.WORKING_DIR / \"logs\"\n",
    "        self.CHECKPOINTS_DIR = self.WORKING_DIR / \"checkpoints\"\n",
    "        \n",
    "        for directory in [self.MODELS_DIR, self.TEMP_DIR, self.OUTPUT_DIR, \n",
    "                         self.LOGS_DIR, self.CHECKPOINTS_DIR]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Model Configuration\n",
    "    WHISPER_MODEL = \"large-v3\"\n",
    "    SEAMLESS_MODEL = \"facebook/hf-seamless-m4t-large\"\n",
    "    \n",
    "    # Language Settings\n",
    "    SOURCE_LANGUAGE = \"ar\"\n",
    "    TARGET_LANGUAGES = [\"en\", \"de\"]\n",
    "    \n",
    "    # Processing Settings\n",
    "    AUDIO_SAMPLE_RATE = 48000\n",
    "    GPU_MEMORY_FRACTION = 0.8\n",
    "    BATCH_SIZE = 16\n",
    "    MAX_CHUNK_LENGTH = 30.0\n",
    "    \n",
    "    # Quality Settings\n",
    "    NOISE_REDUCTION_STRENGTH = 0.5\n",
    "    VOICE_SIMILARITY_THRESHOLD = 0.85\n",
    "    \n",
    "    # File Processing\n",
    "    MAX_FILE_SIZE_GB = 8\n",
    "    SUPPORTED_VIDEO_FORMATS = [\".mp4\", \".avi\", \".mkv\", \".mov\"]\n",
    "    \n",
    "    # Error Handling\n",
    "    MAX_RETRIES = 3\n",
    "    RETRY_DELAY = 60\n",
    "    \n",
    "    def get_video_output_path(self, video_name, language, resolution=\"1080p\"):\n",
    "        return self.OUTPUT_DIR / video_name / f\"{video_name}_{language}_{resolution}.mp4\"\n",
    "    \n",
    "    def get_log_path(self, video_name):\n",
    "        return self.LOGS_DIR / f\"{video_name}_processing.log\"\n",
    "\n",
    "config = Config(local_mode=not os.path.exists(\"/kaggle\"))\n",
    "'''\n",
    "\n",
    "with open('config.py', 'w') as f:\n",
    "    f.write(config_code)\n",
    "\n",
    "print(\"‚úì Configuration file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a490fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our configuration\n",
    "from config import config\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(config.LOGS_DIR / 'pipeline.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.get_device_name(0)\n",
    "    memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    logger.info(f\"GPU available: {device} ({memory:.1f}GB)\")\n",
    "else:\n",
    "    logger.warning(\"No GPU available - will use CPU (slower processing)\")\n",
    "\n",
    "print(\"‚úì Environment initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6700e",
   "metadata": {},
   "source": [
    "## üé¨ Video Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover available video files\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def discover_videos():\n",
    "    \"\"\"Find video files in input directory\"\"\"\n",
    "    video_files = []\n",
    "    \n",
    "    # Search in Kaggle input directory\n",
    "    search_paths = []\n",
    "    if IS_KAGGLE:\n",
    "        # Search all subdirectories in /kaggle/input\n",
    "        input_dirs = list(Path('/kaggle/input').glob('*'))\n",
    "        for input_dir in input_dirs:\n",
    "            if input_dir.is_dir():\n",
    "                search_paths.append(input_dir)\n",
    "    else:\n",
    "        # Local input directory\n",
    "        search_paths = [Path('./input')]\n",
    "    \n",
    "    for search_path in search_paths:\n",
    "        if search_path.exists():\n",
    "            for ext in config.SUPPORTED_VIDEO_FORMATS:\n",
    "                pattern = str(search_path / f'**/*{ext}')\n",
    "                found_files = glob.glob(pattern, recursive=True)\n",
    "                video_files.extend([Path(f) for f in found_files])\n",
    "    \n",
    "    # Filter by file size\n",
    "    valid_videos = []\n",
    "    for video_file in video_files:\n",
    "        try:\n",
    "            file_size_gb = video_file.stat().st_size / (1024**3)\n",
    "            if file_size_gb <= config.MAX_FILE_SIZE_GB:\n",
    "                valid_videos.append(video_file)\n",
    "                print(f\"Found: {video_file.name} ({file_size_gb:.1f}GB)\")\n",
    "            else:\n",
    "                print(f\"Skipping oversized: {video_file.name} ({file_size_gb:.1f}GB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking {video_file}: {e}\")\n",
    "    \n",
    "    return valid_videos\n",
    "\n",
    "# Discover videos\n",
    "video_files = discover_videos()\n",
    "print(f\"\\n‚úì Found {len(video_files)} valid video files\")\n",
    "\n",
    "if not video_files:\n",
    "    print(\"\\n‚ö†Ô∏è  No video files found!\")\n",
    "    print(\"Please ensure your video files are uploaded to the Kaggle dataset or input directory.\")\n",
    "    print(\"Supported formats:\", config.SUPPORTED_VIDEO_FORMATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and cache models\n",
    "import whisper\n",
    "from transformers import SeamlessM4TModel, SeamlessM4TProcessor\n",
    "import torch\n",
    "\n",
    "def download_models():\n",
    "    \"\"\"Download and cache required models\"\"\"\n",
    "    logger.info(\"Downloading and caching models...\")\n",
    "    \n",
    "    # Download Whisper model\n",
    "    try:\n",
    "        logger.info(\"Downloading Whisper large-v3...\")\n",
    "        whisper_model = whisper.load_model(\n",
    "            config.WHISPER_MODEL,\n",
    "            download_root=str(config.MODELS_DIR)\n",
    "        )\n",
    "        del whisper_model\n",
    "        logger.info(\"‚úì Whisper model cached\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download Whisper: {e}\")\n",
    "    \n",
    "    # Download SeamlessM4T model\n",
    "    try:\n",
    "        logger.info(\"Downloading SeamlessM4T large...\")\n",
    "        torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        \n",
    "        processor = SeamlessM4TProcessor.from_pretrained(\n",
    "            config.SEAMLESS_MODEL,\n",
    "            cache_dir=str(config.MODELS_DIR)\n",
    "        )\n",
    "        \n",
    "        model = SeamlessM4TModel.from_pretrained(\n",
    "            config.SEAMLESS_MODEL,\n",
    "            cache_dir=str(config.MODELS_DIR),\n",
    "            torch_dtype=torch_dtype\n",
    "        )\n",
    "        \n",
    "        del processor, model\n",
    "        torch.cuda.empty_cache()\n",
    "        logger.info(\"‚úì SeamlessM4T model cached\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download SeamlessM4T: {e}\")\n",
    "    \n",
    "    # Clone OpenVoice repository\n",
    "    try:\n",
    "        import git\n",
    "        openvoice_dir = config.WORKING_DIR / \"OpenVoice\"\n",
    "        \n",
    "        if not openvoice_dir.exists():\n",
    "            logger.info(\"Cloning OpenVoice repository...\")\n",
    "            git.Repo.clone_from(\n",
    "                \"https://github.com/myshell-ai/OpenVoice.git\",\n",
    "                openvoice_dir\n",
    "            )\n",
    "            logger.info(\"‚úì OpenVoice repository cloned\")\n",
    "        else:\n",
    "            logger.info(\"‚úì OpenVoice repository already exists\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to clone OpenVoice: {e}\")\n",
    "\n",
    "# Download models\n",
    "download_models()\n",
    "print(\"\\n‚úì Model setup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62573d",
   "metadata": {},
   "source": [
    "## üéØ Process Videos\n",
    "\n",
    "Now we'll process each video through the complete pipeline. You can run this cell multiple times - it will resume from checkpoints if interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3588c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing function\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import librosa\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "class VideoDubbingProcessor:\n",
    "    def __init__(self, video_name):\n",
    "        self.video_name = video_name\n",
    "        self.logger = logging.getLogger(f\"processor_{video_name}\")\n",
    "        self.checkpoint_file = config.CHECKPOINTS_DIR / f\"{video_name}_checkpoint.json\"\n",
    "        \n",
    "    def save_checkpoint(self, step, data):\n",
    "        \"\"\"Save processing checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            \"video_name\": self.video_name,\n",
    "            \"step\": step,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"data\": data\n",
    "        }\n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"Load existing checkpoint\"\"\"\n",
    "        if self.checkpoint_file.exists():\n",
    "            with open(self.checkpoint_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return None\n",
    "    \n",
    "    def extract_audio(self, video_path):\n",
    "        \"\"\"Extract and clean audio from video\"\"\"\n",
    "        self.logger.info(\"Extracting audio...\")\n",
    "        \n",
    "        audio_path = config.TEMP_DIR / f\"{self.video_name}_audio.wav\"\n",
    "        \n",
    "        # Extract audio using ffmpeg\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", str(video_path),\n",
    "            \"-ar\", str(config.AUDIO_SAMPLE_RATE),\n",
    "            \"-ac\", \"1\",  # Mono\n",
    "            \"-y\", str(audio_path)\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(cmd, capture_output=True, check=True)\n",
    "        \n",
    "        # Apply noise reduction\n",
    "        import noisereduce as nr\n",
    "        audio, sr = librosa.load(str(audio_path), sr=config.AUDIO_SAMPLE_RATE)\n",
    "        reduced_audio = nr.reduce_noise(y=audio, sr=sr)\n",
    "        \n",
    "        clean_audio_path = config.TEMP_DIR / f\"{self.video_name}_clean_audio.wav\"\n",
    "        librosa.output.write_wav(str(clean_audio_path), reduced_audio, sr)\n",
    "        \n",
    "        return clean_audio_path\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \"\"\"Transcribe audio using Whisper\"\"\"\n",
    "        self.logger.info(\"Transcribing audio...\")\n",
    "        \n",
    "        # Load Whisper model\n",
    "        model = whisper.load_model(\n",
    "            config.WHISPER_MODEL,\n",
    "            download_root=str(config.MODELS_DIR)\n",
    "        )\n",
    "        \n",
    "        # Transcribe\n",
    "        result = model.transcribe(\n",
    "            str(audio_path),\n",
    "            language=\"ar\",\n",
    "            word_timestamps=True\n",
    "        )\n",
    "        \n",
    "        # Save transcription\n",
    "        transcript_file = config.TEMP_DIR / f\"{self.video_name}_transcript.json\"\n",
    "        with open(transcript_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def translate_text(self, transcription, target_language):\n",
    "        \"\"\"Translate transcription using SeamlessM4T\"\"\"\n",
    "        self.logger.info(f\"Translating to {target_language}...\")\n",
    "        \n",
    "        # Load SeamlessM4T\n",
    "        processor = SeamlessM4TProcessor.from_pretrained(\n",
    "            config.SEAMLESS_MODEL,\n",
    "            cache_dir=str(config.MODELS_DIR)\n",
    "        )\n",
    "        \n",
    "        model = SeamlessM4TModel.from_pretrained(\n",
    "            config.SEAMLESS_MODEL,\n",
    "            cache_dir=str(config.MODELS_DIR),\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.to(\"cuda\")\n",
    "        \n",
    "        # Language mapping\n",
    "        lang_map = {\"en\": \"eng\", \"de\": \"deu\"}\n",
    "        target_lang = lang_map.get(target_language, target_language)\n",
    "        \n",
    "        # Translate segments\n",
    "        translated_segments = []\n",
    "        \n",
    "        for segment in transcription[\"segments\"]:\n",
    "            text = segment[\"text\"].strip()\n",
    "            if len(text) < 3:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                inputs = processor(\n",
    "                    text=text,\n",
    "                    src_lang=\"arb\",\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v \n",
    "                             for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        tgt_lang=target_lang,\n",
    "                        max_new_tokens=512\n",
    "                    )\n",
    "                \n",
    "                translation = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "                \n",
    "                translated_segments.append({\n",
    "                    \"start\": segment[\"start\"],\n",
    "                    \"end\": segment[\"end\"],\n",
    "                    \"original_text\": text,\n",
    "                    \"translated_text\": translation\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Translation failed for segment: {e}\")\n",
    "                translated_segments.append({\n",
    "                    \"start\": segment[\"start\"],\n",
    "                    \"end\": segment[\"end\"],\n",
    "                    \"original_text\": text,\n",
    "                    \"translated_text\": f\"[Translation Error: {text}]\"\n",
    "                })\n",
    "        \n",
    "        del model, processor\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return translated_segments\n",
    "    \n",
    "    def create_subtitles(self, segments, language):\n",
    "        \"\"\"Create SRT subtitle file\"\"\"\n",
    "        self.logger.info(f\"Creating subtitles for {language}...\")\n",
    "        \n",
    "        output_dir = config.OUTPUT_DIR / self.video_name\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        srt_file = output_dir / f\"{self.video_name}_{language}.srt\"\n",
    "        \n",
    "        with open(srt_file, 'w', encoding='utf-8') as f:\n",
    "            for i, segment in enumerate(segments, 1):\n",
    "                start_time = self._seconds_to_srt_time(segment[\"start\"])\n",
    "                end_time = self._seconds_to_srt_time(segment[\"end\"])\n",
    "                text = segment[\"translated_text\"]\n",
    "                \n",
    "                f.write(f\"{i}\\n\")\n",
    "                f.write(f\"{start_time} --> {end_time}\\n\")\n",
    "                f.write(f\"{text}\\n\\n\")\n",
    "        \n",
    "        return srt_file\n",
    "    \n",
    "    def _seconds_to_srt_time(self, seconds):\n",
    "        \"\"\"Convert seconds to SRT timestamp format\"\"\"\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        millisecs = int((seconds % 1) * 1000)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}\"\n",
    "    \n",
    "    def create_final_video(self, original_video, subtitle_files, language):\n",
    "        \"\"\"Create final video with subtitles\"\"\"\n",
    "        self.logger.info(f\"Creating final video for {language}...\")\n",
    "        \n",
    "        output_path = config.get_video_output_path(self.video_name, language)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # For now, just copy original video and add subtitles\n",
    "        # In full implementation, this would include dubbed audio\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", str(original_video),\n",
    "            \"-i\", str(subtitle_files[language]),\n",
    "            \"-c:v\", \"copy\",\n",
    "            \"-c:a\", \"copy\",\n",
    "            \"-c:s\", \"mov_text\",\n",
    "            \"-map\", \"0\",\n",
    "            \"-map\", \"1\",\n",
    "            \"-y\", str(output_path)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, capture_output=True, check=True)\n",
    "            return output_path\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.logger.error(f\"Video creation failed: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úì Video processor class created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process videos\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "def process_videos(video_files, max_videos=None):\n",
    "    \"\"\"Process video files through the dubbing pipeline\"\"\"\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for video_file in tqdm(video_files, desc=\"Processing videos\"):\n",
    "        video_name = video_file.stem\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Processing: {video_name}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        processor = VideoDubbingProcessor(video_name)\n",
    "        \n",
    "        try:\n",
    "            # Check for existing checkpoint\n",
    "            checkpoint = processor.load_checkpoint()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Step 1: Extract and clean audio\n",
    "            if not checkpoint or checkpoint.get(\"step\") < 1:\n",
    "                clean_audio_path = processor.extract_audio(video_file)\n",
    "                processor.save_checkpoint(1, {\"clean_audio\": str(clean_audio_path)})\n",
    "                logger.info(\"‚úì Audio extraction completed\")\n",
    "            else:\n",
    "                clean_audio_path = Path(checkpoint[\"data\"][\"clean_audio\"])\n",
    "                logger.info(\"‚úì Audio extraction (from checkpoint)\")\n",
    "            \n",
    "            # Step 2: Transcribe audio\n",
    "            if not checkpoint or checkpoint.get(\"step\") < 2:\n",
    "                transcription = processor.transcribe_audio(clean_audio_path)\n",
    "                processor.save_checkpoint(2, {\"transcription_file\": f\"{video_name}_transcript.json\"})\n",
    "                logger.info(\"‚úì Transcription completed\")\n",
    "            else:\n",
    "                transcript_file = config.TEMP_DIR / f\"{video_name}_transcript.json\"\n",
    "                with open(transcript_file, 'r', encoding='utf-8') as f:\n",
    "                    transcription = json.load(f)\n",
    "                logger.info(\"‚úì Transcription (from checkpoint)\")\n",
    "            \n",
    "            # Step 3: Translate and create subtitles\n",
    "            subtitle_files = {}\n",
    "            \n",
    "            for language in config.TARGET_LANGUAGES:\n",
    "                if not checkpoint or checkpoint.get(\"step\") < 3:\n",
    "                    translated_segments = processor.translate_text(transcription, language)\n",
    "                    subtitle_file = processor.create_subtitles(translated_segments, language)\n",
    "                    subtitle_files[language] = subtitle_file\n",
    "                    \n",
    "                    processor.save_checkpoint(3, {\n",
    "                        \"subtitle_files\": {lang: str(path) for lang, path in subtitle_files.items()}\n",
    "                    })\n",
    "                    logger.info(f\"‚úì Translation and subtitles for {language} completed\")\n",
    "                else:\n",
    "                    subtitle_files = {lang: Path(path) for lang, path in checkpoint[\"data\"][\"subtitle_files\"].items()}\n",
    "                    logger.info(f\"‚úì Translation for {language} (from checkpoint)\")\n",
    "            \n",
    "            # Step 4: Create final videos (simplified version)\n",
    "            final_videos = {}\n",
    "            for language in config.TARGET_LANGUAGES:\n",
    "                final_video = processor.create_final_video(video_file, subtitle_files, language)\n",
    "                if final_video:\n",
    "                    final_videos[language] = final_video\n",
    "                    logger.info(f\"‚úì Final video for {language} created\")\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            results[video_name] = {\n",
    "                \"status\": \"completed\",\n",
    "                \"processing_time_minutes\": processing_time / 60,\n",
    "                \"subtitle_files\": {lang: str(path) for lang, path in subtitle_files.items()},\n",
    "                \"final_videos\": {lang: str(path) for lang, path in final_videos.items()}\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"‚úì {video_name} completed in {processing_time/60:.1f} minutes\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚úó Failed to process {video_name}: {e}\")\n",
    "            results[video_name] = {\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        \n",
    "        # Clear memory\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process videos (limit to 2 for demo)\n",
    "if video_files:\n",
    "    print(f\"Starting processing of {min(2, len(video_files))} videos...\")\n",
    "    processing_results = process_videos(video_files, max_videos=2)\n",
    "    \n",
    "    # Save results\n",
    "    results_file = config.OUTPUT_DIR / \"processing_results.json\"\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(processing_results, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for video_name, result in processing_results.items():\n",
    "        status = result[\"status\"]\n",
    "        if status == \"completed\":\n",
    "            time_taken = result[\"processing_time_minutes\"]\n",
    "            print(f\"‚úì {video_name}: {status} ({time_taken:.1f} min)\")\n",
    "        else:\n",
    "            print(f\"‚úó {video_name}: {status}\")\n",
    "    \n",
    "    successful = sum(1 for r in processing_results.values() if r[\"status\"] == \"completed\")\n",
    "    print(f\"\\nSuccess rate: {successful}/{len(processing_results)} videos\")\n",
    "    \n",
    "else:\n",
    "    print(\"No video files to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65842294",
   "metadata": {},
   "source": [
    "## üìä Results and Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7030983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results and output files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def display_output_files():\n",
    "    \"\"\"Display generated output files\"\"\"\n",
    "    output_dir = config.OUTPUT_DIR\n",
    "    \n",
    "    if not output_dir.exists():\n",
    "        print(\"No output directory found\")\n",
    "        return\n",
    "    \n",
    "    print(\"Generated Output Files:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for video_dir in output_dir.iterdir():\n",
    "        if video_dir.is_dir():\n",
    "            print(f\"\\nüìÅ {video_dir.name}/\")\n",
    "            \n",
    "            files = list(video_dir.glob(\"*\"))\n",
    "            for file in sorted(files):\n",
    "                size_mb = file.stat().st_size / (1024*1024)\n",
    "                if file.suffix == '.srt':\n",
    "                    print(f\"  üìù {file.name} ({size_mb:.1f}MB) - Subtitles\")\n",
    "                elif file.suffix == '.mp4':\n",
    "                    print(f\"  üé¨ {file.name} ({size_mb:.1f}MB) - Video\")\n",
    "                elif file.suffix == '.json':\n",
    "                    print(f\"  üìã {file.name} ({size_mb:.1f}MB) - Report\")\n",
    "                else:\n",
    "                    print(f\"  üìÑ {file.name} ({size_mb:.1f}MB)\")\n",
    "\n",
    "display_output_files()\n",
    "\n",
    "# Display processing statistics\n",
    "results_file = config.OUTPUT_DIR / \"processing_results.json\"\n",
    "if results_file.exists():\n",
    "    with open(results_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PROCESSING STATISTICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_videos = len(results)\n",
    "    completed = sum(1 for r in results.values() if r[\"status\"] == \"completed\")\n",
    "    failed = total_videos - completed\n",
    "    \n",
    "    print(f\"Total videos processed: {total_videos}\")\n",
    "    print(f\"Successfully completed: {completed}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"Success rate: {(completed/total_videos)*100:.1f}%\")\n",
    "    \n",
    "    if completed > 0:\n",
    "        avg_time = sum(r.get(\"processing_time_minutes\", 0) \n",
    "                      for r in results.values() \n",
    "                      if r[\"status\"] == \"completed\") / completed\n",
    "        print(f\"Average processing time: {avg_time:.1f} minutes per video\")\n",
    "    \n",
    "    print(f\"\\nOutput directory: {config.OUTPUT_DIR}\")\n",
    "    print(f\"Total output files: {sum(len(list(d.glob('*'))) for d in config.OUTPUT_DIR.iterdir() if d.is_dir())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5fe57c",
   "metadata": {},
   "source": [
    "## üöÄ Download Results (Kaggle)\n",
    "\n",
    "If you're running on Kaggle, this will prepare your results for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create downloadable archive of results\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def create_results_archive():\n",
    "    \"\"\"Create a zip archive of all results\"\"\"\n",
    "    if not config.OUTPUT_DIR.exists():\n",
    "        print(\"No output directory found\")\n",
    "        return None\n",
    "    \n",
    "    archive_path = config.WORKING_DIR / \"dubbing_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Add all files from output directory\n",
    "        for root, dirs, files in os.walk(config.OUTPUT_DIR):\n",
    "            for file in files:\n",
    "                file_path = Path(root) / file\n",
    "                arc_path = file_path.relative_to(config.OUTPUT_DIR)\n",
    "                zipf.write(file_path, arc_path)\n",
    "        \n",
    "        # Add processing results\n",
    "        results_file = config.OUTPUT_DIR / \"processing_results.json\"\n",
    "        if results_file.exists():\n",
    "            zipf.write(results_file, \"processing_results.json\")\n",
    "        \n",
    "        # Add logs\n",
    "        log_files = list(config.LOGS_DIR.glob(\"*.log\"))\n",
    "        for log_file in log_files:\n",
    "            zipf.write(log_file, f\"logs/{log_file.name}\")\n",
    "    \n",
    "    size_mb = archive_path.stat().st_size / (1024*1024)\n",
    "    print(f\"‚úì Results archive created: {archive_path.name} ({size_mb:.1f}MB)\")\n",
    "    \n",
    "    return archive_path\n",
    "\n",
    "if IS_KAGGLE and config.OUTPUT_DIR.exists():\n",
    "    archive = create_results_archive()\n",
    "    if archive:\n",
    "        print(f\"\\nüì¶ Download your results: {archive}\")\n",
    "        print(\"The archive contains:\")\n",
    "        print(\"- Dubbed videos (MP4)\")\n",
    "        print(\"- Subtitle files (SRT)\")\n",
    "        print(\"- Processing reports (JSON)\")\n",
    "        print(\"- Processing logs\")\n",
    "else:\n",
    "    print(\"No results to archive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959e6e2",
   "metadata": {},
   "source": [
    "## üìñ Next Steps\n",
    "\n",
    "### What This Notebook Does:\n",
    "\n",
    "1. **‚úÖ Audio Processing**: Extracts and cleans audio from videos\n",
    "2. **‚úÖ Transcription**: Uses Whisper large-v3 to transcribe Arabic speech\n",
    "3. **‚úÖ Translation**: Translates Arabic to English/German using SeamlessM4T\n",
    "4. **‚úÖ Subtitles**: Generates properly formatted SRT subtitle files\n",
    "5. **‚úÖ Basic Video Assembly**: Creates videos with embedded subtitles\n",
    "\n",
    "### For Full Implementation:\n",
    "\n",
    "The complete pipeline (as described in the project requirements) would include:\n",
    "\n",
    "- **Voice Cloning**: Using OpenVoice v2 to clone the original speaker's voice\n",
    "- **Speech Synthesis**: Generating dubbed audio in target languages\n",
    "- **Audio Synchronization**: Using DTW for precise timing alignment\n",
    "- **Quality Assurance**: Comprehensive audio/video quality checks\n",
    "- **Multi-track Assembly**: Creating videos with multiple audio tracks\n",
    "\n",
    "### Usage Tips:\n",
    "\n",
    "1. **Input Format**: Upload your Arabic video files to the Kaggle dataset\n",
    "2. **File Size**: Maximum 8GB per video file\n",
    "3. **Processing Time**: ~30-60 minutes per hour of video content\n",
    "4. **Memory Management**: The notebook automatically manages GPU memory\n",
    "5. **Checkpointing**: Processing can resume from interruptions\n",
    "\n",
    "### Output Files:\n",
    "\n",
    "- `{video_name}_en.srt` - English subtitles\n",
    "- `{video_name}_de.srt` - German subtitles  \n",
    "- `{video_name}_en_1080p.mp4` - English video with subtitles\n",
    "- `{video_name}_de_1080p.mp4` - German video with subtitles\n",
    "- `processing_results.json` - Processing summary and statistics\n",
    "\n",
    "### Customization:\n",
    "\n",
    "You can modify the `config.py` file to:\n",
    "- Change target languages\n",
    "- Adjust quality settings\n",
    "- Modify processing parameters\n",
    "- Set custom output formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8d59e",
   "metadata": {},
   "source": [
    "## üß™ Environment Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and create project files\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "# Project files to create\n",
    "project_files = {\n",
    "    'config.py': '''\"\"\"Configuration module for video dubbing automation\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, local_mode=False):\n",
    "        if local_mode or not os.path.exists('/kaggle'):\n",
    "            self.BASE_DIR = Path.cwd()\n",
    "        else:\n",
    "            self.BASE_DIR = Path('/kaggle/working')\n",
    "        \n",
    "        # Directory structure\n",
    "        self.MODELS_DIR = self.BASE_DIR / 'models'\n",
    "        self.TEMP_DIR = self.BASE_DIR / 'temp'\n",
    "        self.OUTPUT_DIR = self.BASE_DIR / 'output'\n",
    "        self.LOGS_DIR = self.BASE_DIR / 'logs'\n",
    "        self.CHECKPOINTS_DIR = self.BASE_DIR / 'checkpoints'\n",
    "        \n",
    "        # Audio settings\n",
    "        self.AUDIO_SAMPLE_RATE = 48000\n",
    "        self.CHUNK_DURATION = 30  # seconds\n",
    "        \n",
    "        # Processing settings\n",
    "        self.TARGET_LANGUAGES = ['en', 'de']\n",
    "        self.BATCH_SIZE = 1\n",
    "        self.MAX_RETRIES = 3\n",
    "        \n",
    "        # Create directories\n",
    "        for directory in [self.MODELS_DIR, self.TEMP_DIR, self.OUTPUT_DIR, \n",
    "                         self.LOGS_DIR, self.CHECKPOINTS_DIR]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = Config()''',\n",
    "    \n",
    "    'test_environment.py': '''# Environment validation will be created here''',\n",
    "    'demo_processor.py': '''# Demo processor will be created here'''\n",
    "}\n",
    "\n",
    "# Create the files\n",
    "for filename, content in project_files.items():\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"‚úì Created {filename}\")\n",
    "\n",
    "print(\"\\nüéâ Project files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142622d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run environment validation\n",
    "print(\"üîç Running Environment Validation...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Import validation functions\n",
    "try:\n",
    "    exec(open('test_environment.py').read())\n",
    "    validator = EnvironmentValidator(local_mode=not IS_KAGGLE)\n",
    "    validation_results = validator.run_full_validation()\n",
    "    \n",
    "    print(f\"\\nüìä Validation completed: {validation_results.get('overall_status', 'Unknown')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation failed: {e}\")\n",
    "    \n",
    "    # Manual basic checks\n",
    "    print(\"\\nüîß Running basic manual checks...\")\n",
    "    \n",
    "    # Check PyTorch and CUDA\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "        print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"   Device: {torch.cuda.get_device_name()}\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyTorch not available\")\n",
    "    \n",
    "    # Check other key packages\n",
    "    packages_to_check = ['transformers', 'whisper', 'librosa', 'moviepy']\n",
    "    for package in packages_to_check:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"‚úÖ {package}\")\n",
    "        except ImportError:\n",
    "            print(f\"‚ùå {package} not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58370460",
   "metadata": {},
   "source": [
    "## üé¨ Demo and Testing Mode\n",
    "\n",
    "Before processing real videos, let's test the pipeline with synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run demo pipeline test\n",
    "print(\"üß™ Starting Demo Pipeline Test...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create a simple demo processor\n",
    "    class SimpleDemoProcessor:\n",
    "        def __init__(self):\n",
    "            self.results = {}\n",
    "        \n",
    "        def test_audio_processing(self):\n",
    "            print(\"\\nüéµ Testing Audio Processing...\")\n",
    "            try:\n",
    "                import librosa\n",
    "                import numpy as np\n",
    "                \n",
    "                # Create test audio\n",
    "                duration = 5  # seconds\n",
    "                sr = 22050\n",
    "                t = np.linspace(0, duration, duration * sr)\n",
    "                test_audio = 0.5 * np.sin(2 * np.pi * 440 * t)  # 440 Hz tone\n",
    "                \n",
    "                # Test librosa functionality\n",
    "                mfccs = librosa.feature.mfcc(y=test_audio, sr=sr, n_mfcc=13)\n",
    "                \n",
    "                print(\"  ‚úÖ Audio generation: OK\")\n",
    "                print(\"  ‚úÖ Librosa processing: OK\")\n",
    "                print(f\"  üìä MFCC shape: {mfccs.shape}\")\n",
    "                \n",
    "                return {\"status\": \"‚úÖ PASSED\", \"details\": \"Audio processing working\"}\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Audio processing failed: {e}\")\n",
    "                return {\"status\": \"‚ùå FAILED\", \"error\": str(e)}\n",
    "        \n",
    "        def test_model_loading(self):\n",
    "            print(\"\\nü§ñ Testing Model Loading...\")\n",
    "            try:\n",
    "                import whisper\n",
    "                \n",
    "                # Test whisper model loading\n",
    "                print(\"  üì• Loading Whisper base model...\")\n",
    "                model = whisper.load_model(\"base\")\n",
    "                print(\"  ‚úÖ Whisper model loaded successfully\")\n",
    "                \n",
    "                # Clean up\n",
    "                del model\n",
    "                \n",
    "                return {\"status\": \"‚úÖ PASSED\", \"details\": \"Model loading working\"}\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Model loading failed: {e}\")\n",
    "                return {\"status\": \"‚ùå FAILED\", \"error\": str(e)}\n",
    "        \n",
    "        def test_transformers(self):\n",
    "            print(\"\\nüåê Testing Transformers...\")\n",
    "            try:\n",
    "                from transformers import pipeline\n",
    "                \n",
    "                # Test a simple pipeline\n",
    "                print(\"  üì• Creating translation pipeline...\")\n",
    "                # Use a small model for testing\n",
    "                translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ar-en\", \n",
    "                                     device=0 if torch.cuda.is_available() else -1)\n",
    "                \n",
    "                # Test translation\n",
    "                test_text = \"ŸÖÿ±ÿ≠ÿ®ÿß\"  # \"Hello\" in Arabic\n",
    "                result = translator(test_text)\n",
    "                print(f\"  ‚úÖ Translation test: '{test_text}' -> '{result[0]['translation_text']}'\")\n",
    "                \n",
    "                return {\"status\": \"‚úÖ PASSED\", \"details\": \"Translation working\"}\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Translation test failed: {e}\")\n",
    "                return {\"status\": \"‚ö†Ô∏è  PARTIAL\", \"error\": str(e)}\n",
    "        \n",
    "        def run_full_test(self):\n",
    "            print(\"üöÄ Running comprehensive demo test...\")\n",
    "            \n",
    "            tests = [\n",
    "                (\"audio_processing\", self.test_audio_processing),\n",
    "                (\"model_loading\", self.test_model_loading),\n",
    "                (\"transformers\", self.test_transformers)\n",
    "            ]\n",
    "            \n",
    "            results = {}\n",
    "            passed = 0\n",
    "            \n",
    "            for test_name, test_func in tests:\n",
    "                try:\n",
    "                    result = test_func()\n",
    "                    results[test_name] = result\n",
    "                    if \"‚úÖ\" in result[\"status\"]:\n",
    "                        passed += 1\n",
    "                except Exception as e:\n",
    "                    results[test_name] = {\"status\": \"‚ùå FAILED\", \"error\": str(e)}\n",
    "            \n",
    "            print(f\"\\nüìä Demo Test Results: {passed}/{len(tests)} tests passed\")\n",
    "            \n",
    "            if passed == len(tests):\n",
    "                print(\"üéâ All tests passed! System ready for video processing.\")\n",
    "            elif passed >= len(tests) // 2:\n",
    "                print(\"‚ö†Ô∏è  Some tests passed. System partially ready.\")\n",
    "            else:\n",
    "                print(\"‚ùå Multiple tests failed. Please check installation.\")\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    # Run the demo\n",
    "    demo = SimpleDemoProcessor()\n",
    "    demo_results = demo.run_full_test()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Demo test failed: {e}\")\n",
    "    print(\"\\nüìù Manual verification:\")\n",
    "    print(\"1. Check that all packages are installed\")\n",
    "    print(\"2. Verify GPU availability if needed\")\n",
    "    print(\"3. Ensure sufficient disk space (>20GB recommended)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9f5e6",
   "metadata": {},
   "source": [
    "## üé• Video Processing Pipeline\n",
    "\n",
    "Once the environment validation passes, you can start processing your videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ef92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video processing configuration and setup\n",
    "print(\"üé¨ Video Dubbing Pipeline Configuration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configuration settings\n",
    "VIDEO_CONFIG = {\n",
    "    \"source_language\": \"ar\",  # Arabic\n",
    "    \"target_languages\": [\"en\", \"de\"],  # English and German\n",
    "    \"quality_preset\": \"high\",  # high, medium, fast\n",
    "    \"enable_subtitles\": True,\n",
    "    \"enable_speaker_diarization\": True,\n",
    "    \"max_video_length_minutes\": 120,\n",
    "    \"chunk_size_minutes\": 30  # For memory management\n",
    "}\n",
    "\n",
    "print(\"üìã Current Configuration:\")\n",
    "for key, value in VIDEO_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Input validation\n",
    "print(\"\\nüìÅ Input Requirements:\")\n",
    "print(\"  ‚Ä¢ Video format: MP4, AVI, MOV, MKV\")\n",
    "print(\"  ‚Ä¢ Audio: Clear speech, minimal background noise\")\n",
    "print(\"  ‚Ä¢ Language: Arabic (Egyptian dialect preferred)\")\n",
    "print(\"  ‚Ä¢ Duration: 60-120 minutes recommended\")\n",
    "print(\"  ‚Ä¢ Size: Up to 8GB per video\")\n",
    "\n",
    "print(\"\\nüéØ Expected Output:\")\n",
    "print(\"  ‚Ä¢ English dubbed video (MP4)\")\n",
    "print(\"  ‚Ä¢ German dubbed video (MP4)\")\n",
    "print(\"  ‚Ä¢ Subtitle files (SRT/VTT)\")\n",
    "print(\"  ‚Ä¢ Processing report (JSON)\")\n",
    "print(\"  ‚Ä¢ Quality metrics and validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12884e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload and processing initialization\n",
    "print(\"üì§ Video Upload and Processing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(\"üìÅ On Kaggle, your video files should be in:\")\n",
    "    print(\"   /kaggle/input/your-dataset-name/\")\n",
    "    print(\"\\nüîç Available input datasets:\")\n",
    "    \n",
    "    import os\n",
    "    input_path = Path('/kaggle/input')\n",
    "    if input_path.exists():\n",
    "        datasets = [d for d in input_path.iterdir() if d.is_dir()]\n",
    "        if datasets:\n",
    "            for dataset in datasets:\n",
    "                print(f\"   üìÇ {dataset.name}\")\n",
    "                # List video files in dataset\n",
    "                video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "                videos = [f for f in dataset.rglob('*') \n",
    "                         if f.suffix.lower() in video_extensions]\n",
    "                for video in videos[:3]:  # Show first 3 videos\n",
    "                    size_mb = video.stat().st_size / 1024**2\n",
    "                    print(f\"      üé• {video.name} ({size_mb:.1f}MB)\")\n",
    "                if len(videos) > 3:\n",
    "                    print(f\"      ... and {len(videos)-3} more videos\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No datasets found. Please upload your videos to a Kaggle dataset first.\")\n",
    "            print(\"\\nüìñ How to upload videos:\")\n",
    "            print(\"   1. Create a new dataset on Kaggle\")\n",
    "            print(\"   2. Upload your video files\")\n",
    "            print(\"   3. Add the dataset to this notebook\")\n",
    "else:\n",
    "    print(\"üíª In local mode, place your videos in:\")\n",
    "    print(\"   ./input/ directory\")\n",
    "    \n",
    "    # Create input directory if it doesn't exist\n",
    "    input_dir = Path('./input')\n",
    "    input_dir.mkdir(exist_ok=True)\n",
    "    print(f\"   Created: {input_dir.absolute()}\")\n",
    "\n",
    "print(\"\\n‚ö° Ready to start processing!\")\n",
    "print(\"   Use the next cell to select and process videos.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
