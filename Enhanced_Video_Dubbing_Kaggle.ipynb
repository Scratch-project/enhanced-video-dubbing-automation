{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12173723,"sourceType":"datasetVersion","datasetId":7667190},{"sourceId":12189162,"sourceType":"datasetVersion","datasetId":7677601},{"sourceId":12189351,"sourceType":"datasetVersion","datasetId":7677738},{"sourceId":12196685,"sourceType":"datasetVersion","datasetId":7682824}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Enhanced Video Dubbing Automation\n\n## Arabic to English/German Video Dubbing Pipeline\n\nThis notebook provides a complete automated pipeline for dubbing Arabic lecture/presentation videos into English and German, optimized for Kaggle's GPU environment.\n\n### Features:\n- **Step 0**: Environment setup and model caching\n- **Step 1**: Audio extraction and noise reduction\n- **Step 2**: Transcription with speaker diarization\n- **Step 3**: Translation using Meta SeamlessM4T v2\n- **Step 4**: Voice cloning with OpenVoice v2\n- **Step 5**: Intelligent audio-video synchronization\n- **Step 6**: Subtitle generation and integration\n- **Step 7**: Quality assurance and final assembly\n- **Step 8**: Batch processing with checkpointing\n\n### Requirements:\n- Kaggle GPU environment (P100/T4/V100)\n- Video files up to 8GB each\n- Arabic source language (Egyptian dialect supported)\n- Output: English and German dubbed videos with subtitles","metadata":{}},{"cell_type":"markdown","source":"## ğŸ“‹ Setup and Configuration","metadata":{}},{"cell_type":"code","source":"# Check if we're running on Kaggle and setup environment\nimport os\nimport sys\nfrom pathlib import Path\n\nIS_KAGGLE = os.path.exists('/kaggle')\nprint(f\"ğŸŒ Running on Kaggle: {IS_KAGGLE}\")\n\nif IS_KAGGLE:\n    print(f\"ğŸ“ Working directory: /kaggle/working\")\n    print(f\"ğŸ“¥ Input directory: /kaggle/input\")\n    \n    # Check available GPU\n    print(\"\\nğŸ–¥ï¸  GPU Information:\")\n    try:\n        import subprocess\n        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n                              capture_output=True, text=True)\n        if result.returncode == 0:\n            for line in result.stdout.strip().split('\\n'):\n                if line.strip():\n                    gpu_name, memory = line.split(', ')\n                    print(f\"   ğŸš€ {gpu_name} ({memory}MB)\")\n        else:\n            print(\"   âŒ No GPU detected\")\n    except:\n        print(\"   â“ GPU status unknown\")\nelse:\n    print(\"ğŸ’» Running in local environment\")\n    print(\"   Note: For local use, consider using the individual Python files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:51:56.199101Z","iopub.execute_input":"2025-06-16T20:51:56.199395Z","iopub.status.idle":"2025-06-16T20:51:56.212954Z","shell.execute_reply.started":"2025-06-16T20:51:56.199365Z","shell.execute_reply":"2025-06-16T20:51:56.211826Z"}},"outputs":[{"name":"stdout","text":"ğŸŒ Running on Kaggle: True\nğŸ“ Working directory: /kaggle/working\nğŸ“¥ Input directory: /kaggle/input\n\nğŸ–¥ï¸  GPU Information:\n   â“ GPU status unknown\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#  FIXED KAGGLE INSTALLER v2.3 â€” Video Dubbing Pipeline (PyTorch Installation Fixed)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#  âœ… Fixed PyTorch installation â€¢ âœ… Better error handling â€¢ âœ… Kaggle optimization\n#  âœ… Step-by-step debugging â€¢ âœ… Fallback strategies â€¢ âœ… 2025 compatibility\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nimport subprocess, sys, importlib, pathlib, re, types, os, time, shutil\nfrom datetime import datetime\nimport json\n\n# Environment detection\nIS_KAGGLE = any(\"/kaggle\" in p for p in sys.path) or os.path.exists('/kaggle')\nPYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n\nprint(f\"ğŸ¬ FIXED Video Dubbing Installer v2.3\")\nprint(f\"ğŸ“ Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\")\nprint(f\"ğŸ Python: {PYTHON_VERSION}\")\nprint(f\"ğŸ“‚ Working directory: {os.getcwd()}\")\n\n# Enhanced helper functions\ndef sh(cmd, check=True, timeout=300, verbose=True):\n    if verbose:\n        print(f\"$ {cmd}\")\n    try:\n        result = subprocess.run(cmd, shell=True, check=check, \n                              capture_output=True, text=True, timeout=timeout)\n        if verbose and result.stdout:\n            print(f\"   {result.stdout.strip()}\")\n        if result.stderr and \"warning\" not in result.stderr.lower():\n            if verbose:\n                print(f\"âš ï¸  {result.stderr.strip()}\")\n        return result\n    except subprocess.TimeoutExpired:\n        print(f\"â±ï¸  Command timed out after {timeout}s\")\n        return None\n    except subprocess.CalledProcessError as e:\n        print(f\"âŒ Command failed with code {e.returncode}\")\n        if e.stdout:\n            print(f\"   stdout: {e.stdout.strip()}\")\n        if e.stderr:\n            print(f\"   stderr: {e.stderr.strip()}\")\n        if check:\n            raise\n        return e\n\ndef check_pip_install_success(package_name):\n    \"\"\"Verify if a package was actually installed\"\"\"\n    try:\n        result = sh(f\"python -m pip show {package_name}\", check=False, verbose=False)\n        return result and result.returncode == 0\n    except:\n        return False\n\ndef force_pip_install(package, max_retries=3, use_cache=False):\n    \"\"\"Force install a package with multiple strategies\"\"\"\n    print(f\"ğŸ”§ Installing {package}...\")\n    \n    # Base flags\n    flags = []\n    if IS_KAGGLE:\n        flags.extend([\"--user\", \"--no-warn-script-location\"])\n    \n    if not use_cache:\n        flags.append(\"--no-cache-dir\")\n    \n    # Strategy 1: Normal install\n    for attempt in range(max_retries):\n        try:\n            cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + flags + [package]\n            result = subprocess.run(cmd, check=True, timeout=300, \n                                  capture_output=True, text=True)\n            \n            # Verify installation\n            pkg_name = re.split(r\"[<>=!]\", package)[0]\n            if check_pip_install_success(pkg_name):\n                print(f\"  âœ… {package} installed successfully\")\n                return True\n            else:\n                print(f\"  âš ï¸  Installation reported success but package not found\")\n                \n        except Exception as e:\n            print(f\"  âŒ Attempt {attempt + 1} failed: {str(e)[:100]}...\")\n            if attempt < max_retries - 1:\n                time.sleep(2)\n    \n    # Strategy 2: Force reinstall\n    print(f\"  ğŸ”„ Trying force reinstall...\")\n    try:\n        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"--no-deps\"] + flags + [package]\n        subprocess.run(cmd, check=True, timeout=300)\n        \n        pkg_name = re.split(r\"[<>=!]\", package)[0]\n        if check_pip_install_success(pkg_name):\n            print(f\"  âœ… {package} force installed successfully\")\n            return True\n    except Exception as e:\n        print(f\"  âŒ Force install failed: {str(e)[:100]}...\")\n    \n    return False\n\ndef detect_gpu_and_cuda():\n    \"\"\"Enhanced GPU and CUDA detection\"\"\"\n    gpu_info = {\"has_gpu\": False, \"cuda_version\": None, \"gpu_name\": None, \"cuda_major\": None}\n    \n    print(\"ğŸ” Detecting GPU and CUDA...\")\n    \n    try:\n        # Check for nvidia-smi\n        result = sh(\"which nvidia-smi\", check=False, verbose=False)\n        if not result or result.returncode != 0:\n            print(\"  ğŸ’» nvidia-smi not found - assuming CPU environment\")\n            return gpu_info\n            \n        # Check for GPU\n        result = sh(\"nvidia-smi --query-gpu=name --format=csv,noheader\", check=False, verbose=False)\n        if result and result.returncode == 0:\n            gpu_info[\"has_gpu\"] = True\n            gpu_info[\"gpu_name\"] = result.stdout.strip().split('\\n')[0]\n            print(f\"  ğŸ–¥ï¸  GPU found: {gpu_info['gpu_name']}\")\n            \n            # Check CUDA version\n            cuda_result = sh(\"nvcc --version\", check=False, verbose=False)\n            if cuda_result and cuda_result.returncode == 0:\n                match = re.search(r'release (\\d+)\\.(\\d+)', cuda_result.stdout)\n                if match:\n                    major, minor = match.groups()\n                    gpu_info[\"cuda_version\"] = f\"{major}.{minor}\"\n                    gpu_info[\"cuda_major\"] = int(major)\n                    print(f\"  ğŸ” CUDA version: {gpu_info['cuda_version']}\")\n            else:\n                print(\"  âš ï¸  nvcc not found - CUDA may not be properly installed\")\n        else:\n            print(\"  ğŸ’» No GPU detected\")\n            \n    except Exception as e:\n        print(f\"  âš ï¸  GPU detection error: {e}\")\n    \n    return gpu_info\n\n# Detect environment\ngpu_info = detect_gpu_and_cuda()\n\n# System dependencies for Kaggle\nif IS_KAGGLE:\n    print(\"ğŸ“¦ Installing system dependencies...\")\n    sh(\"apt-get -qq update\", check=False)\n    sh(\"apt-get -qq install -y ffmpeg git libsndfile1-dev portaudio19-dev\", check=False)\n\n# Enhanced cleanup\nprint(\"ğŸ§¹ Enhanced cleanup...\")\nCLEANUP_PACKAGES = [\n    \"torch\", \"torchaudio\", \"torchvision\", \"torch-audio\", \"torch-vision\",\n    \"speechbrain\", \"whisper\", \"openai-whisper\", \"dtw\", \"dtw-python\", \n    \"noisereduce\", \"hyperpyyaml\", \"ruamel.yaml\"\n]\n\nfor pkg in CLEANUP_PACKAGES:\n    sh(f\"python -m pip uninstall -y -q {pkg}\", check=False, verbose=False)\n\n# Clear pip cache\nsh(\"python -m pip cache purge\", check=False, verbose=False)\n\n# Update pip itself\nprint(\"ğŸ”§ Updating pip...\")\nsh(\"python -m pip install --upgrade pip setuptools wheel\", check=False)\n\n# Install base dependencies first\nprint(\"ğŸ“¦ Installing base dependencies...\")\nBASE_DEPS = [\n    \"numpy>=1.24.0,<2.0.0\",\n    \"packaging>=21.0\",\n    \"setuptools>=60.0.0\",\n    \"wheel>=0.38.0\",\n]\n\nfor dep in BASE_DEPS:\n    force_pip_install(dep)\n\n# FIXED PyTorch installation\nprint(\"ğŸ”¥ FIXED PyTorch Installation...\")\n\ndef install_pytorch_fixed():\n    \"\"\"Fixed PyTorch installation with proper error handling\"\"\"\n    \n    # Determine the right PyTorch version and index\n    if not gpu_info[\"has_gpu\"]:\n        print(\"  ğŸ’» Installing CPU-only PyTorch...\")\n        index_url = \"https://download.pytorch.org/whl/cpu\"\n        torch_version = \"torch torchaudio\"\n    else:\n        cuda_major = gpu_info.get(\"cuda_major\", 11)\n        print(f\"  ğŸš€ Installing PyTorch for CUDA {cuda_major}.x...\")\n        \n        if cuda_major >= 12:\n            index_url = \"https://download.pytorch.org/whl/cu121\"  # Use cu121 for broad compatibility\n            torch_version = \"torch torchaudio\"\n        else:\n            index_url = \"https://download.pytorch.org/whl/cu118\"\n            torch_version = \"torch torchaudio\"\n    \n    # Install PyTorch with proper flags\n    cmd_parts = [\n        sys.executable, \"-m\", \"pip\", \"install\", \n        \"--no-cache-dir\", \"--index-url\", index_url\n    ]\n    \n    if IS_KAGGLE:\n        cmd_parts.extend([\"--user\", \"--no-warn-script-location\"])\n    \n    cmd_parts.extend(torch_version.split())\n    \n    print(f\"  ğŸ“¦ Command: {' '.join(cmd_parts)}\")\n    \n    try:\n        result = subprocess.run(cmd_parts, check=True, timeout=600, \n                              capture_output=True, text=True)\n        print(\"  âœ… PyTorch installation completed\")\n        \n        # Verify installation\n        time.sleep(2)  # Give time for installation to settle\n        \n        # Test import\n        try:\n            import torch\n            print(f\"  âœ… PyTorch import successful\")\n            print(f\"  ğŸ” PyTorch version: {torch.__version__}\")\n            \n            if torch.cuda.is_available():\n                print(f\"  ğŸš€ CUDA available: {torch.cuda.device_count()} devices\")\n                print(f\"  ğŸ¯ Current device: {torch.cuda.get_device_name(0)}\")\n            else:\n                print(f\"  ğŸ’» CUDA not available, using CPU\")\n            \n            return True\n            \n        except ImportError as e:\n            print(f\"  âŒ PyTorch import failed: {e}\")\n            return False\n            \n    except subprocess.TimeoutExpired:\n        print(\"  â±ï¸  PyTorch installation timed out\")\n        return False\n    except subprocess.CalledProcessError as e:\n        print(f\"  âŒ PyTorch installation failed: {e}\")\n        if e.stdout:\n            print(f\"     stdout: {e.stdout[-200:]}\")  # Last 200 chars\n        if e.stderr:\n            print(f\"     stderr: {e.stderr[-200:]}\")  # Last 200 chars\n        return False\n\n# Attempt PyTorch installation\npytorch_success = install_pytorch_fixed()\n\n# Fallback to CPU if GPU installation failed\nif not pytorch_success and gpu_info[\"has_gpu\"]:\n    print(\"ğŸ”„ GPU PyTorch failed, trying CPU version...\")\n    gpu_info[\"has_gpu\"] = False  # Force CPU installation\n    pytorch_success = install_pytorch_fixed()\n\nif not pytorch_success:\n    print(\"ğŸš¨ Critical: PyTorch installation completely failed!\")\n    print(\"ğŸ”§ Manual fix needed - try restarting kernel and running again\")\n\n# Core ML packages\nprint(\"ğŸ¤– Installing core ML packages...\")\nCORE_ML = [\n    \"transformers>=4.30.0,<4.50.0\",\n    \"tokenizers>=0.13.0\",\n    \"safetensors>=0.3.0\",\n    \"accelerate>=0.20.0\",\n    \"openai-whisper>=20231117\",\n]\n\nml_success = 0\nfor package in CORE_ML:\n    if force_pip_install(package):\n        ml_success += 1\n\n# Audio/Video processing packages\nprint(\"ğŸµ Installing audio/video packages...\")\nAV_PACKAGES = [\n    \"librosa>=0.10.0\",\n    \"soundfile>=0.12.1\",\n    \"moviepy==1.0.3\",\n    \"opencv-python-headless>=4.8.0\",\n    \"ffmpeg-python>=0.2.0\",\n]\n\nav_success = 0\nfor package in AV_PACKAGES:\n    if force_pip_install(package):\n        av_success += 1\n\n# Utility packages\nprint(\"ğŸ”§ Installing utility packages...\")\nUTILITIES = [\n    \"tqdm>=4.65.0\",\n    \"requests>=2.31.0\",\n    \"pandas>=1.5.0\",\n    \"numpy>=1.24.0,<2.0.0\",\n    \"scipy>=1.10.0\",\n    \"matplotlib>=3.7.0\",\n    \"psutil>=5.9.0\",\n]\n\nutil_success = 0\nfor package in UTILITIES:\n    if force_pip_install(package):\n        util_success += 1\n\n# Optional packages\nprint(\"ğŸ”§ Installing optional packages...\")\nOPTIONAL = [\n    \"speechbrain>=0.5.0\",\n    \"dtw-python>=1.3.0\",\n    \"noisereduce>=3.0.0\",\n    \"hyperpyyaml>=1.2.0\",\n]\n\noptional_success = 0\nfor package in OPTIONAL:\n    if force_pip_install(package):\n        optional_success += 1\n\n# Comprehensive testing\nprint(\"ğŸ§ª Comprehensive Testing...\")\n\ndef test_import_with_info(module_name, import_name=None, test_func=None):\n    \"\"\"Test import with detailed information\"\"\"\n    try:\n        if import_name:\n            module = importlib.import_module(import_name)\n        else:\n            module = importlib.import_module(module_name)\n        \n        info = \"\"\n        if hasattr(module, '__version__'):\n            info = f\" v{module.__version__}\"\n        \n        if test_func:\n            test_result = test_func(module)\n            if test_result:\n                info += f\" ({test_result})\"\n        \n        print(f\"  âœ… {module_name}{info}\")\n        return True\n        \n    except Exception as e:\n        error_msg = str(e)[:50] + \"...\" if len(str(e)) > 50 else str(e)\n        print(f\"  âŒ {module_name}: {error_msg}\")\n        return False\n\n# Test critical imports\nprint(\"ğŸ” Testing critical imports...\")\ntest_results = {}\n\n# PyTorch\ntest_results[\"torch\"] = test_import_with_info(\"torch\", test_func=lambda m: \n    f\"CUDA: {m.cuda.is_available()}, Devices: {m.cuda.device_count()}\" if hasattr(m, 'cuda') else \"CPU only\")\n\n# Whisper\ntest_results[\"whisper\"] = test_import_with_info(\"whisper\", test_func=lambda m: \n    f\"{len(m.available_models())} models\" if hasattr(m, 'available_models') else None)\n\n# Other critical packages\ncritical_packages = [\n    (\"transformers\", \"transformers\"),\n    (\"librosa\", \"librosa\"),\n    (\"cv2\", \"cv2\"),\n    (\"moviepy\", \"moviepy\"),\n    (\"soundfile\", \"soundfile\"),\n]\n\nfor display_name, import_name in critical_packages:\n    test_results[display_name] = test_import_with_info(display_name, import_name)\n\n# Functionality tests\nprint(\"ğŸ”¬ Testing functionality...\")\n\n# Test PyTorch operations\ntry:\n    import torch\n    x = torch.randn(3, 3)\n    y = torch.matmul(x, x)\n    if torch.cuda.is_available():\n        x_gpu = x.cuda()\n        y_gpu = torch.matmul(x_gpu, x_gpu)\n        functionality_test_gpu = True\n    else:\n        functionality_test_gpu = False\n    print(f\"  âœ… PyTorch tensor operations (GPU: {functionality_test_gpu})\")\nexcept Exception as e:\n    print(f\"  âŒ PyTorch operations: {e}\")\n\n# Test Whisper\ntry:\n    import whisper\n    model = whisper.load_model(\"base\")\n    print(\"  âœ… Whisper model loading\")\nexcept Exception as e:\n    print(f\"  âŒ Whisper model loading: {e}\")\n\n# Test audio processing\ntry:\n    import librosa\n    import numpy as np\n    dummy_audio = np.random.randn(1000)\n    mfcc = librosa.feature.mfcc(y=dummy_audio, sr=22050)\n    print(\"  âœ… Audio processing\")\nexcept Exception as e:\n    print(f\"  âŒ Audio processing: {e}\")\n\n# Final summary\nprint(f\"\\nğŸ“Š INSTALLATION SUMMARY\")\nprint(f\"{'='*70}\")\n\npassed = sum(test_results.values())\ntotal = len(test_results)\nsuccess_rate = (passed / total) * 100\n\nprint(f\"ğŸ§ª Critical imports: {passed}/{total} ({success_rate:.1f}%)\")\nprint(f\"ğŸ¤– ML packages: {ml_success}/{len(CORE_ML)}\")\nprint(f\"ğŸµ AV packages: {av_success}/{len(AV_PACKAGES)}\")\nprint(f\"ğŸ”§ Utilities: {util_success}/{len(UTILITIES)}\")\nprint(f\"ğŸ“¦ Optional: {optional_success}/{len(OPTIONAL)}\")\n\n# System status\nprint(f\"\\nğŸ¯ SYSTEM STATUS:\")\nif pytorch_success and test_results.get(\"torch\", False):\n    try:\n        import torch\n        if torch.cuda.is_available():\n            print(f\"  ğŸš€ GPU Acceleration: ENABLED\")\n            print(f\"     Device: {torch.cuda.get_device_name(0)}\")\n            print(f\"     Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n        else:\n            print(f\"  ğŸ’» GPU Acceleration: DISABLED (CPU mode)\")\n    except:\n        print(f\"  âš ï¸  PyTorch status unclear\")\nelse:\n    print(f\"  âŒ PyTorch: FAILED\")\n\n# Pipeline readiness\ncore_ready = all(test_results.get(pkg, False) for pkg in [\"torch\", \"whisper\", \"transformers\"])\nav_ready = all(test_results.get(pkg, False) for pkg in [\"librosa\", \"cv2\", \"moviepy\"])\n\nif core_ready:\n    print(f\"  âœ… ML Pipeline: READY\")\nelse:\n    print(f\"  âŒ ML Pipeline: INCOMPLETE\")\n\nif av_ready:\n    print(f\"  âœ… AV Processing: READY\")\nelse:\n    print(f\"  âŒ AV Processing: INCOMPLETE\")\n\n# Final verdict\nif pytorch_success and core_ready and av_ready:\n    print(f\"\\nğŸ‰ INSTALLATION SUCCESSFUL!\")\n    print(f\"ğŸš€ Ready for video dubbing pipeline!\")\n    print(f\"ğŸ’¡ All systems operational\")\nelif pytorch_success and core_ready:\n    print(f\"\\nâš ï¸  MOSTLY SUCCESSFUL\")\n    print(f\"ğŸ”§ Core ML working, some AV issues\")\n    print(f\"ğŸ’¡ Should work with basic functionality\")\nelse:\n    print(f\"\\nâŒ CRITICAL ISSUES DETECTED\")\n    print(f\"ğŸ”§ PyTorch or core ML components failed\")\n    print(f\"ğŸ’¡ Kernel restart recommended\")\n\nprint(f\"\\nğŸ“‹ TROUBLESHOOTING TIPS:\")\nprint(f\"  1. If PyTorch failed: Restart kernel and try again\")\nprint(f\"  2. If imports fail: Check Python path and permissions\")\nprint(f\"  3. If CUDA issues: Verify GPU is available in Kaggle settings\")\nprint(f\"  4. For persistent issues: Switch to CPU-only mode\")\n\nprint(f\"\\nâ° Installation completed: {datetime.now().strftime('%H:%M:%S')}\")\nprint(f\"ğŸ”„ Kernel restart recommended for best results\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:51:56.630350Z","iopub.execute_input":"2025-06-16T20:51:56.630709Z","iopub.status.idle":"2025-06-16T20:54:52.566694Z","shell.execute_reply.started":"2025-06-16T20:51:56.630681Z","shell.execute_reply":"2025-06-16T20:54:52.565588Z"}},"outputs":[{"name":"stdout","text":"ğŸ¬ FIXED Video Dubbing Installer v2.3\nğŸ“ Environment: Kaggle\nğŸ Python: 3.11\nğŸ“‚ Working directory: /kaggle/working\nğŸ” Detecting GPU and CUDA...\n  ğŸ’» nvidia-smi not found - assuming CPU environment\nğŸ“¦ Installing system dependencies...\n$ apt-get -qq update\nâš ï¸  W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n$ apt-get -qq install -y ffmpeg git libsndfile1-dev portaudio19-dev\nğŸ§¹ Enhanced cleanup...\nğŸ”§ Updating pip...\n$ python -m pip install --upgrade pip setuptools wheel\n   Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.9.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\nğŸ“¦ Installing base dependencies...\nğŸ”§ Installing numpy>=1.24.0,<2.0.0...\n  âœ… numpy>=1.24.0,<2.0.0 installed successfully\nğŸ”§ Installing packaging>=21.0...\n  âœ… packaging>=21.0 installed successfully\nğŸ”§ Installing setuptools>=60.0.0...\n  âœ… setuptools>=60.0.0 installed successfully\nğŸ”§ Installing wheel>=0.38.0...\n  âœ… wheel>=0.38.0 installed successfully\nğŸ”¥ FIXED PyTorch Installation...\n  ğŸ’» Installing CPU-only PyTorch...\n  ğŸ“¦ Command: /usr/bin/python3 -m pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu --user --no-warn-script-location torch torchaudio\n  âœ… PyTorch installation completed\n  âœ… PyTorch import successful\n  ğŸ” PyTorch version: 2.7.1+cpu\n  ğŸ’» CUDA not available, using CPU\nğŸ¤– Installing core ML packages...\nğŸ”§ Installing transformers>=4.30.0,<4.50.0...\n  âœ… transformers>=4.30.0,<4.50.0 installed successfully\nğŸ”§ Installing tokenizers>=0.13.0...\n  âœ… tokenizers>=0.13.0 installed successfully\nğŸ”§ Installing safetensors>=0.3.0...\n  âœ… safetensors>=0.3.0 installed successfully\nğŸ”§ Installing accelerate>=0.20.0...\n  âœ… accelerate>=0.20.0 installed successfully\nğŸ”§ Installing openai-whisper>=20231117...\n  âœ… openai-whisper>=20231117 installed successfully\nğŸµ Installing audio/video packages...\nğŸ”§ Installing librosa>=0.10.0...\n  âœ… librosa>=0.10.0 installed successfully\nğŸ”§ Installing soundfile>=0.12.1...\n  âœ… soundfile>=0.12.1 installed successfully\nğŸ”§ Installing moviepy==1.0.3...\n  âœ… moviepy==1.0.3 installed successfully\nğŸ”§ Installing opencv-python-headless>=4.8.0...\n  âœ… opencv-python-headless>=4.8.0 installed successfully\nğŸ”§ Installing ffmpeg-python>=0.2.0...\n  âœ… ffmpeg-python>=0.2.0 installed successfully\nğŸ”§ Installing utility packages...\nğŸ”§ Installing tqdm>=4.65.0...\n  âœ… tqdm>=4.65.0 installed successfully\nğŸ”§ Installing requests>=2.31.0...\n  âœ… requests>=2.31.0 installed successfully\nğŸ”§ Installing pandas>=1.5.0...\n  âœ… pandas>=1.5.0 installed successfully\nğŸ”§ Installing numpy>=1.24.0,<2.0.0...\n  âœ… numpy>=1.24.0,<2.0.0 installed successfully\nğŸ”§ Installing scipy>=1.10.0...\n  âœ… scipy>=1.10.0 installed successfully\nğŸ”§ Installing matplotlib>=3.7.0...\n  âœ… matplotlib>=3.7.0 installed successfully\nğŸ”§ Installing psutil>=5.9.0...\n  âœ… psutil>=5.9.0 installed successfully\nğŸ”§ Installing optional packages...\nğŸ”§ Installing speechbrain>=0.5.0...\n  âœ… speechbrain>=0.5.0 installed successfully\nğŸ”§ Installing dtw-python>=1.3.0...\n  âœ… dtw-python>=1.3.0 installed successfully\nğŸ”§ Installing noisereduce>=3.0.0...\n  âœ… noisereduce>=3.0.0 installed successfully\nğŸ”§ Installing hyperpyyaml>=1.2.0...\n  âœ… hyperpyyaml>=1.2.0 installed successfully\nğŸ§ª Comprehensive Testing...\nğŸ” Testing critical imports...\n  âœ… torch v2.7.1+cpu (CUDA: False, Devices: 0)\n  âœ… whisper v20240930 (14 models)\n  âœ… transformers v4.49.0\n  âœ… librosa v0.11.0\n  âœ… cv2 v4.11.0\n  âœ… moviepy v1.0.3\n  âœ… soundfile v0.13.1\nğŸ”¬ Testing functionality...\n  âœ… PyTorch tensor operations (GPU: False)\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 129MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"  âœ… Whisper model loading\n  âœ… Audio processing\n\nğŸ“Š INSTALLATION SUMMARY\n======================================================================\nğŸ§ª Critical imports: 7/7 (100.0%)\nğŸ¤– ML packages: 5/5\nğŸµ AV packages: 5/5\nğŸ”§ Utilities: 7/7\nğŸ“¦ Optional: 4/4\n\nğŸ¯ SYSTEM STATUS:\n  ğŸ’» GPU Acceleration: DISABLED (CPU mode)\n  âœ… ML Pipeline: READY\n  âœ… AV Processing: READY\n\nğŸ‰ INSTALLATION SUCCESSFUL!\nğŸš€ Ready for video dubbing pipeline!\nğŸ’¡ All systems operational\n\nğŸ“‹ TROUBLESHOOTING TIPS:\n  1. If PyTorch failed: Restart kernel and try again\n  2. If imports fail: Check Python path and permissions\n  3. If CUDA issues: Verify GPU is available in Kaggle settings\n  4. For persistent issues: Switch to CPU-only mode\n\nâ° Installation completed: 20:54:52\nğŸ”„ Kernel restart recommended for best results\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1000\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ğŸ› ï¸ Kaggle Environment Setup and Path Configuration\nprint(\"ğŸ”§ Configuring Kaggle Environment\")\nprint(\"=\" * 40)\n\nif IS_KAGGLE:\n    # Ensure user-installed packages are in path\n    import site\n    import sys\n    \n    # Add user site-packages to Python path\n    user_site = site.getusersitepackages()\n    if user_site not in sys.path:\n        sys.path.insert(0, user_site)\n        print(f\"âœ… Added user site-packages to path: {user_site}\")\n    \n    # Also add common Kaggle user install locations\n    common_paths = [\n        \"/root/.local/lib/python3.10/site-packages\",\n        \"/home/.local/lib/python3.10/site-packages\",\n        \"/opt/conda/lib/python3.10/site-packages\"\n    ]\n    \n    for path in common_paths:\n        if os.path.exists(path) and path not in sys.path:\n            sys.path.insert(0, path)\n            print(f\"âœ… Added path: {path}\")\n    \n    # Refresh importlib cache\n    import importlib\n    importlib.invalidate_caches()\n    \n    # Set environment variables for better package detection\n    os.environ['PYTHONPATH'] = ':'.join(sys.path)\n    \n    print(f\"ğŸ” Current Python paths:\")\n    for i, path in enumerate(sys.path[:5]):  # Show first 5 paths\n        print(f\"   {i+1}. {path}\")\n    if len(sys.path) > 5:\n        print(f\"   ... and {len(sys.path)-5} more paths\")\n\nelse:\n    print(\"ğŸ’» Local environment - no Kaggle-specific setup needed\")\n\n# Memory and GPU setup\nprint(f\"\\nğŸ–¥ï¸  GPU and Memory Configuration:\")\ntry:\n    import torch\n    if torch.cuda.is_available():\n        device_count = torch.cuda.device_count()\n        current_device = torch.cuda.current_device()\n        device_name = torch.cuda.get_device_name(current_device)\n        \n        print(f\"âœ… GPU Available: {device_name}\")\n        print(f\"   Device count: {device_count}\")\n        print(f\"   Current device: {current_device}\")\n        \n        # Clear any existing GPU memory\n        torch.cuda.empty_cache()\n        \n        # Get memory info\n        memory_allocated = torch.cuda.memory_allocated(current_device) / 1024**3\n        memory_reserved = torch.cuda.memory_reserved(current_device) / 1024**3\n        \n        print(f\"   Memory allocated: {memory_allocated:.2f} GB\")\n        print(f\"   Memory reserved: {memory_reserved:.2f} GB\")\n        \n        # Set memory fraction to prevent OOM\n        if not hasattr(torch.cuda, '_initialized') or not torch.cuda._initialized:\n            torch.cuda.set_per_process_memory_fraction(0.9)  # Use 90% of GPU memory\n            print(f\"   Set memory fraction to 90%\")\n        \n    else:\n        print(\"âš ï¸  No GPU available - will use CPU (much slower)\")\n        \nexcept ImportError:\n    print(\"âŒ PyTorch not available\")\n\nprint(f\"\\nğŸ¯ Environment ready for video dubbing pipeline!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:59:34.341604Z","iopub.execute_input":"2025-06-16T20:59:34.343285Z","iopub.status.idle":"2025-06-16T20:59:34.357950Z","shell.execute_reply.started":"2025-06-16T20:59:34.343245Z","shell.execute_reply":"2025-06-16T20:59:34.356997Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Configuring Kaggle Environment\n========================================\nğŸ” Current Python paths:\n   1. /kaggle/working\n   2. /kaggle/lib/kagglegym\n   3. /kaggle/lib\n   4. /usr/lib/python311.zip\n   5. /usr/lib/python3.11\n   ... and 8 more paths\n\nğŸ–¥ï¸  GPU and Memory Configuration:\nâš ï¸  No GPU available - will use CPU (much slower)\n\nğŸ¯ Environment ready for video dubbing pipeline!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Create project files in working directory\nimport os\nfrom pathlib import Path\n\n# Set working directory\nif IS_KAGGLE:\n    os.chdir('/kaggle/working')\nelse:\n    # Create local working directory\n    Path('./working').mkdir(exist_ok=True)\n    os.chdir('./working')\n\nprint(f\"Current working directory: {os.getcwd()}\")\n\n# Create necessary directories\ndirectories = ['models', 'temp', 'output', 'logs', 'checkpoints', 'scripts']\n\nfor directory in directories:\n    Path(directory).mkdir(exist_ok=True)\n    print(f\"âœ“ Created directory: {directory}/\")\n\nprint(\"\\nâœ… Directory structure ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:59:40.235954Z","iopub.execute_input":"2025-06-16T20:59:40.236308Z","iopub.status.idle":"2025-06-16T20:59:40.245051Z","shell.execute_reply.started":"2025-06-16T20:59:40.236286Z","shell.execute_reply":"2025-06-16T20:59:40.243848Z"}},"outputs":[{"name":"stdout","text":"Current working directory: /kaggle/working\nâœ“ Created directory: models/\nâœ“ Created directory: temp/\nâœ“ Created directory: output/\nâœ“ Created directory: logs/\nâœ“ Created directory: checkpoints/\nâœ“ Created directory: scripts/\n\nâœ… Directory structure ready!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## ğŸš€ Initialize Dubbing Pipeline","metadata":{}},{"cell_type":"code","source":"# Write the main configuration file\nconfig_code = '''\n\"\"\"Enhanced Video Dubbing Configuration\"\"\"\nimport os\nfrom pathlib import Path\n\nclass Config:\n    def __init__(self, local_mode=False):\n        self.local_mode = local_mode\n        self.setup_directories()\n    \n    def setup_directories(self):\n        if self.local_mode or not os.path.exists(\"/kaggle\"):\n            self.WORKING_DIR = Path(\"./working\")\n            self.INPUT_DIR = Path(\"./input\")\n        else:\n            self.WORKING_DIR = Path(\"/kaggle/working\")\n            self.INPUT_DIR = Path(\"/kaggle/input\")\n        \n        self.MODELS_DIR = self.WORKING_DIR / \"models\"\n        self.TEMP_DIR = self.WORKING_DIR / \"temp\"\n        self.OUTPUT_DIR = self.WORKING_DIR / \"output\"\n        self.LOGS_DIR = self.WORKING_DIR / \"logs\"\n        self.CHECKPOINTS_DIR = self.WORKING_DIR / \"checkpoints\"\n        \n        for directory in [self.MODELS_DIR, self.TEMP_DIR, self.OUTPUT_DIR, \n                         self.LOGS_DIR, self.CHECKPOINTS_DIR]:\n            directory.mkdir(parents=True, exist_ok=True)\n    \n    # Model Configuration\n    WHISPER_MODEL = \"large-v3\"\n    SEAMLESS_MODEL = \"facebook/hf-seamless-m4t-large\"\n    \n    # Language Settings\n    SOURCE_LANGUAGE = \"ar\"\n    TARGET_LANGUAGES = [\"en\", \"de\"]\n    \n    # Processing Settings\n    AUDIO_SAMPLE_RATE = 48000\n    GPU_MEMORY_FRACTION = 0.8\n    BATCH_SIZE = 16\n    MAX_CHUNK_LENGTH = 30.0\n    \n    # Quality Settings\n    NOISE_REDUCTION_STRENGTH = 0.5\n    VOICE_SIMILARITY_THRESHOLD = 0.85\n    \n    # File Processing\n    MAX_FILE_SIZE_GB = 8\n    SUPPORTED_VIDEO_FORMATS = [\".mp4\", \".avi\", \".mkv\", \".mov\"]\n    \n    # Error Handling\n    MAX_RETRIES = 3\n    RETRY_DELAY = 60\n    \n    def get_video_output_path(self, video_name, language, resolution=\"1080p\"):\n        return self.OUTPUT_DIR / video_name / f\"{video_name}_{language}_{resolution}.mp4\"\n    \n    def get_log_path(self, video_name):\n        return self.LOGS_DIR / f\"{video_name}_processing.log\"\n\nconfig = Config(local_mode=not os.path.exists(\"/kaggle\"))\n'''\n\nwith open('config.py', 'w') as f:\n    f.write(config_code)\n\nprint(\"âœ“ Configuration file created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:59:42.943087Z","iopub.execute_input":"2025-06-16T20:59:42.943425Z","iopub.status.idle":"2025-06-16T20:59:42.951617Z","shell.execute_reply.started":"2025-06-16T20:59:42.943402Z","shell.execute_reply":"2025-06-16T20:59:42.950633Z"}},"outputs":[{"name":"stdout","text":"âœ“ Configuration file created\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Import our configuration\nfrom config import config\nimport torch\nimport logging\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(config.LOGS_DIR / 'pipeline.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\n# Check GPU availability\nif torch.cuda.is_available():\n    device = torch.cuda.get_device_name(0)\n    memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    logger.info(f\"GPU available: {device} ({memory:.1f}GB)\")\nelse:\n    logger.warning(\"No GPU available - will use CPU (slower processing)\")\n\nprint(\"âœ“ Environment initialized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:59:45.382874Z","iopub.execute_input":"2025-06-16T20:59:45.383279Z","iopub.status.idle":"2025-06-16T20:59:45.394010Z","shell.execute_reply.started":"2025-06-16T20:59:45.383247Z","shell.execute_reply":"2025-06-16T20:59:45.392744Z"}},"outputs":[{"name":"stdout","text":"âœ“ Environment initialized\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## ğŸ¬ Video Processing Pipeline","metadata":{}},{"cell_type":"code","source":"# Discover available video files\nimport glob\nfrom pathlib import Path\n\ndef discover_videos():\n    \"\"\"Find video files in input directory\"\"\"\n    video_files = []\n    \n    # Search in Kaggle input directory\n    search_paths = []\n    if IS_KAGGLE:\n        # Search all subdirectories in /kaggle/input\n        input_dirs = list(Path('/kaggle/input').glob('*'))\n        for input_dir in input_dirs:\n            if input_dir.is_dir():\n                search_paths.append(input_dir)\n    else:\n        # Local input directory\n        search_paths = [Path('./input')]\n    \n    for search_path in search_paths:\n        if search_path.exists():\n            for ext in config.SUPPORTED_VIDEO_FORMATS:\n                pattern = str(search_path / f'**/*{ext}')\n                found_files = glob.glob(pattern, recursive=True)\n                video_files.extend([Path(f) for f in found_files])\n    \n    # Filter by file size\n    valid_videos = []\n    for video_file in video_files:\n        try:\n            file_size_gb = video_file.stat().st_size / (1024**3)\n            if file_size_gb <= config.MAX_FILE_SIZE_GB:\n                valid_videos.append(video_file)\n                print(f\"Found: {video_file.name} ({file_size_gb:.1f}GB)\")\n            else:\n                print(f\"Skipping oversized: {video_file.name} ({file_size_gb:.1f}GB)\")\n        except Exception as e:\n            print(f\"Error checking {video_file}: {e}\")\n    \n    return valid_videos\n\n# Discover videos\nvideo_files = discover_videos()\nprint(f\"\\nâœ“ Found {len(video_files)} valid video files\")\n\nif not video_files:\n    print(\"\\nâš ï¸  No video files found!\")\n    print(\"Please ensure your video files are uploaded to the Kaggle dataset or input directory.\")\n    print(\"Supported formats:\", config.SUPPORTED_VIDEO_FORMATS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T20:59:47.291889Z","iopub.execute_input":"2025-06-16T20:59:47.292747Z","iopub.status.idle":"2025-06-16T20:59:47.321954Z","shell.execute_reply.started":"2025-06-16T20:59:47.292709Z","shell.execute_reply":"2025-06-16T20:59:47.320862Z"}},"outputs":[{"name":"stdout","text":"Found: 1   .mp4 (0.2GB)\n\nâœ“ Found 1 valid video files\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## ğŸ¯ Process Videos\n\nNow we'll process each video through the complete pipeline. You can run this cell multiple times - it will resume from checkpoints if interrupted.","metadata":{}},{"cell_type":"code","source":"# Main processing function\nimport subprocess\nimport json\nimport time\nfrom datetime import datetime\nimport librosa\nimport numpy as np\nimport gc\n\nclass VideoDubbingProcessor:\n    def __init__(self, video_name):\n        self.video_name = video_name\n        self.logger = logging.getLogger(f\"processor_{video_name}\")\n        self.checkpoint_file = config.CHECKPOINTS_DIR / f\"{video_name}_checkpoint.json\"\n        \n    def save_checkpoint(self, step, data):\n        \"\"\"Save processing checkpoint\"\"\"\n        checkpoint = {\n            \"video_name\": self.video_name,\n            \"step\": step,\n            \"timestamp\": datetime.now().isoformat(),\n            \"data\": data\n        }\n        with open(self.checkpoint_file, 'w') as f:\n            json.dump(checkpoint, f, indent=2)\n    \n    def load_checkpoint(self):\n        \"\"\"Load existing checkpoint\"\"\"\n        if self.checkpoint_file.exists():\n            with open(self.checkpoint_file, 'r') as f:\n                return json.load(f)\n        return None\n    \n    def extract_audio(self, video_path):\n        \"\"\"Extract and clean audio from video\"\"\"\n        self.logger.info(\"Extracting audio...\")\n        \n        audio_path = config.TEMP_DIR / f\"{self.video_name}_audio.wav\"\n        \n        # Extract audio using ffmpeg\n        cmd = [\n            \"ffmpeg\", \"-i\", str(video_path),\n            \"-ar\", str(config.AUDIO_SAMPLE_RATE),\n            \"-ac\", \"1\",  # Mono\n            \"-y\", str(audio_path)\n        ]\n        \n        subprocess.run(cmd, capture_output=True, check=True)\n        \n        # Apply noise reduction\n        import noisereduce as nr\n        audio, sr = librosa.load(str(audio_path), sr=config.AUDIO_SAMPLE_RATE)\n        reduced_audio = nr.reduce_noise(y=audio, sr=sr)\n        \n        clean_audio_path = config.TEMP_DIR / f\"{self.video_name}_clean_audio.wav\"\n        librosa.output.write_wav(str(clean_audio_path), reduced_audio, sr)\n        \n        return clean_audio_path\n    \n    def transcribe_audio(self, audio_path):\n        \"\"\"Transcribe audio using Whisper\"\"\"\n        self.logger.info(\"Transcribing audio...\")\n        \n        # Load Whisper model\n        model = whisper.load_model(\n            config.WHISPER_MODEL,\n            download_root=str(config.MODELS_DIR)\n        )\n        \n        # Transcribe\n        result = model.transcribe(\n            str(audio_path),\n            language=\"ar\",\n            word_timestamps=True\n        )\n        \n        # Save transcription\n        transcript_file = config.TEMP_DIR / f\"{self.video_name}_transcript.json\"\n        with open(transcript_file, 'w', encoding='utf-8') as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)\n        \n        del model\n        torch.cuda.empty_cache()\n        \n        return result\n    \n    def translate_text(self, transcription, target_language):\n        \"\"\"Translate transcription using SeamlessM4T\"\"\"\n        self.logger.info(f\"Translating to {target_language}...\")\n        \n        # Load SeamlessM4T\n        processor = SeamlessM4TProcessor.from_pretrained(\n            config.SEAMLESS_MODEL,\n            cache_dir=str(config.MODELS_DIR)\n        )\n        \n        model = SeamlessM4TModel.from_pretrained(\n            config.SEAMLESS_MODEL,\n            cache_dir=str(config.MODELS_DIR),\n            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n        )\n        \n        if torch.cuda.is_available():\n            model = model.to(\"cuda\")\n        \n        # Language mapping\n        lang_map = {\"en\": \"eng\", \"de\": \"deu\"}\n        target_lang = lang_map.get(target_language, target_language)\n        \n        # Translate segments\n        translated_segments = []\n        \n        for segment in transcription[\"segments\"]:\n            text = segment[\"text\"].strip()\n            if len(text) < 3:\n                continue\n            \n            try:\n                inputs = processor(\n                    text=text,\n                    src_lang=\"arb\",\n                    return_tensors=\"pt\"\n                )\n                \n                if torch.cuda.is_available():\n                    inputs = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v \n                             for k, v in inputs.items()}\n                \n                with torch.no_grad():\n                    outputs = model.generate(\n                        **inputs,\n                        tgt_lang=target_lang,\n                        max_new_tokens=512\n                    )\n                \n                translation = processor.decode(outputs[0], skip_special_tokens=True)\n                \n                translated_segments.append({\n                    \"start\": segment[\"start\"],\n                    \"end\": segment[\"end\"],\n                    \"original_text\": text,\n                    \"translated_text\": translation\n                })\n                \n            except Exception as e:\n                self.logger.warning(f\"Translation failed for segment: {e}\")\n                translated_segments.append({\n                    \"start\": segment[\"start\"],\n                    \"end\": segment[\"end\"],\n                    \"original_text\": text,\n                    \"translated_text\": f\"[Translation Error: {text}]\"\n                })\n        \n        del model, processor\n        torch.cuda.empty_cache()\n        \n        return translated_segments\n    \n    def create_subtitles(self, segments, language):\n        \"\"\"Create SRT subtitle file\"\"\"\n        self.logger.info(f\"Creating subtitles for {language}...\")\n        \n        output_dir = config.OUTPUT_DIR / self.video_name\n        output_dir.mkdir(parents=True, exist_ok=True)\n        \n        srt_file = output_dir / f\"{self.video_name}_{language}.srt\"\n        \n        with open(srt_file, 'w', encoding='utf-8') as f:\n            for i, segment in enumerate(segments, 1):\n                start_time = self._seconds_to_srt_time(segment[\"start\"])\n                end_time = self._seconds_to_srt_time(segment[\"end\"])\n                text = segment[\"translated_text\"]\n                \n                f.write(f\"{i}\\n\")\n                f.write(f\"{start_time} --> {end_time}\\n\")\n                f.write(f\"{text}\\n\\n\")\n        \n        return srt_file\n    \n    def _seconds_to_srt_time(self, seconds):\n        \"\"\"Convert seconds to SRT timestamp format\"\"\"\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        secs = int(seconds % 60)\n        millisecs = int((seconds % 1) * 1000)\n        return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}\"\n    \n    def create_final_video(self, original_video, subtitle_files, language):\n        \"\"\"Create final video with subtitles\"\"\"\n        self.logger.info(f\"Creating final video for {language}...\")\n        \n        output_path = config.get_video_output_path(self.video_name, language)\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        # For now, just copy original video and add subtitles\n        # In full implementation, this would include dubbed audio\n        cmd = [\n            \"ffmpeg\",\n            \"-i\", str(original_video),\n            \"-i\", str(subtitle_files[language]),\n            \"-c:v\", \"copy\",\n            \"-c:a\", \"copy\",\n            \"-c:s\", \"mov_text\",\n            \"-map\", \"0\",\n            \"-map\", \"1\",\n            \"-y\", str(output_path)\n        ]\n        \n        try:\n            subprocess.run(cmd, capture_output=True, check=True)\n            return output_path\n        except subprocess.CalledProcessError as e:\n            self.logger.error(f\"Video creation failed: {e}\")\n            return None\n\nprint(\"âœ“ Video processor class created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Process videos\nfrom tqdm.notebook import tqdm\nimport time\nfrom pathlib import Path\nimport json\nimport gc\nimport torch\n\n# Add this section to define video_files before using it\ndef get_video_files(input_directory, extensions=None):\n    \"\"\"Find all video files in the input directory\"\"\"\n    if extensions is None:\n        extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']\n    \n    input_path = Path(input_directory)\n    video_files = []\n    \n    for ext in extensions:\n        video_files.extend(input_path.glob(f\"*{ext}\"))\n        video_files.extend(input_path.glob(f\"*{ext.upper()}\"))\n    \n    return sorted(video_files)\n\ndef process_videos(video_files, max_videos=None):\n    \"\"\"Process video files through the dubbing pipeline\"\"\"\n    \n    if max_videos:\n        video_files = video_files[:max_videos]\n    \n    results = {}\n    \n    for video_file in tqdm(video_files, desc=\"Processing videos\"):\n        video_name = video_file.stem\n        logger.info(f\"\\n{'='*60}\")\n        logger.info(f\"Processing: {video_name}\")\n        logger.info(f\"{'='*60}\")\n        \n        processor = VideoDubbingProcessor(video_name)\n        \n        try:\n            # Check for existing checkpoint\n            checkpoint = processor.load_checkpoint()\n            \n            start_time = time.time()\n            \n            # Step 1: Extract and clean audio\n            if not checkpoint or checkpoint.get(\"step\") < 1:\n                clean_audio_path = processor.extract_audio(video_file)\n                processor.save_checkpoint(1, {\"clean_audio\": str(clean_audio_path)})\n                logger.info(\"âœ“ Audio extraction completed\")\n            else:\n                clean_audio_path = Path(checkpoint[\"data\"][\"clean_audio\"])\n                logger.info(\"âœ“ Audio extraction (from checkpoint)\")\n            \n            # Step 2: Transcribe audio\n            if not checkpoint or checkpoint.get(\"step\") < 2:\n                transcription = processor.transcribe_audio(clean_audio_path)\n                processor.save_checkpoint(2, {\"transcription_file\": f\"{video_name}_transcript.json\"})\n                logger.info(\"âœ“ Transcription completed\")\n            else:\n                transcript_file = config.TEMP_DIR / f\"{video_name}_transcript.json\"\n                with open(transcript_file, 'r', encoding='utf-8') as f:\n                    transcription = json.load(f)\n                logger.info(\"âœ“ Transcription (from checkpoint)\")\n            \n            # Step 3: Translate and create subtitles\n            subtitle_files = {}\n            \n            for language in config.TARGET_LANGUAGES:\n                if not checkpoint or checkpoint.get(\"step\") < 3:\n                    translated_segments = processor.translate_text(transcription, language)\n                    subtitle_file = processor.create_subtitles(translated_segments, language)\n                    subtitle_files[language] = subtitle_file\n                    \n                    processor.save_checkpoint(3, {\n                        \"subtitle_files\": {lang: str(path) for lang, path in subtitle_files.items()}\n                    })\n                    logger.info(f\"âœ“ Translation and subtitles for {language} completed\")\n                else:\n                    subtitle_files = {lang: Path(path) for lang, path in checkpoint[\"data\"][\"subtitle_files\"].items()}\n                    logger.info(f\"âœ“ Translation for {language} (from checkpoint)\")\n            \n            # Step 4: Create final videos (simplified version)\n            final_videos = {}\n            for language in config.TARGET_LANGUAGES:\n                final_video = processor.create_final_video(video_file, subtitle_files, language)\n                if final_video:\n                    final_videos[language] = final_video\n                    logger.info(f\"âœ“ Final video for {language} created\")\n            \n            processing_time = time.time() - start_time\n            \n            results[video_name] = {\n                \"status\": \"completed\",\n                \"processing_time_minutes\": processing_time / 60,\n                \"subtitle_files\": {lang: str(path) for lang, path in subtitle_files.items()},\n                \"final_videos\": {lang: str(path) for lang, path in final_videos.items()}\n            }\n            \n            logger.info(f\"âœ“ {video_name} completed in {processing_time/60:.1f} minutes\")\n            \n        except Exception as e:\n            logger.error(f\"âœ— Failed to process {video_name}: {e}\")\n            results[video_name] = {\n                \"status\": \"failed\",\n                \"error\": str(e)\n            }\n        \n        # Clear memory\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    return results\n\n# Define video_files before using it\ntry:\n    # Option 1: Get video files from a specific directory\n    # Replace 'your_input_directory' with the actual path to your videos\n    INPUT_DIR = \"/kaggle/input/outofthebox\"  # Change this to your video directory\n    video_files = get_video_files(INPUT_DIR)\n    \n    # Option 2: If you already have a list of video file paths, uncomment and modify:\n    # video_files = [\n    #     Path(\"path/to/video1.mp4\"),\n    #     Path(\"path/to/video2.mp4\"),\n    #     # Add more video paths as needed\n    # ]\n    \n    # Option 3: If config has an INPUT_DIR defined, uncomment:\n    # video_files = get_video_files(config.INPUT_DIR)\n    \nexcept Exception as e:\n    print(f\"Error finding video files: {e}\")\n    video_files = []\n\n# Process videos (limit to 2 for demo)\nif video_files:\n    print(f\"Found {len(video_files)} video files\")\n    print(f\"Starting processing of {min(2, len(video_files))} videos...\")\n    processing_results = process_videos(video_files, max_videos=2)\n    \n    # Save results\n    results_file = config.OUTPUT_DIR / \"processing_results.json\"\n    with open(results_file, 'w') as f:\n        json.dump(processing_results, f, indent=2)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"PROCESSING SUMMARY\")\n    print(\"=\"*60)\n    \n    for video_name, result in processing_results.items():\n        status = result[\"status\"]\n        if status == \"completed\":\n            time_taken = result[\"processing_time_minutes\"]\n            print(f\"âœ“ {video_name}: {status} ({time_taken:.1f} min)\")\n        else:\n            print(f\"âœ— {video_name}: {status}\")\n    \n    successful = sum(1 for r in processing_results.values() if r[\"status\"] == \"completed\")\n    print(f\"\\nSuccess rate: {successful}/{len(processing_results)} videos\")\n    \nelse:\n    print(\"No video files found to process\")\n    print(\"Please check:\")\n    print(\"1. The INPUT_DIR path is correct\")\n    print(\"2. Video files exist in the specified directory\")\n    print(\"3. Video files have supported extensions (.mp4, .avi, .mov, etc.)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Š Results and Output Files","metadata":{}},{"cell_type":"code","source":"# Display results and output files\nimport os\nfrom pathlib import Path\n\ndef display_output_files():\n    \"\"\"Display generated output files\"\"\"\n    output_dir = config.OUTPUT_DIR\n    \n    if not output_dir.exists():\n        print(\"No output directory found\")\n        return\n    \n    print(\"Generated Output Files:\")\n    print(\"=\"*50)\n    \n    for video_dir in output_dir.iterdir():\n        if video_dir.is_dir():\n            print(f\"\\nğŸ“ {video_dir.name}/\")\n            \n            files = list(video_dir.glob(\"*\"))\n            for file in sorted(files):\n                size_mb = file.stat().st_size / (1024*1024)\n                if file.suffix == '.srt':\n                    print(f\"  ğŸ“ {file.name} ({size_mb:.1f}MB) - Subtitles\")\n                elif file.suffix == '.mp4':\n                    print(f\"  ğŸ¬ {file.name} ({size_mb:.1f}MB) - Video\")\n                elif file.suffix == '.json':\n                    print(f\"  ğŸ“‹ {file.name} ({size_mb:.1f}MB) - Report\")\n                else:\n                    print(f\"  ğŸ“„ {file.name} ({size_mb:.1f}MB)\")\n\ndisplay_output_files()\n\n# Display processing statistics\nresults_file = config.OUTPUT_DIR / \"processing_results.json\"\nif results_file.exists():\n    with open(results_file, 'r') as f:\n        results = json.load(f)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"PROCESSING STATISTICS\")\n    print(\"=\"*50)\n    \n    total_videos = len(results)\n    completed = sum(1 for r in results.values() if r[\"status\"] == \"completed\")\n    failed = total_videos - completed\n    \n    print(f\"Total videos processed: {total_videos}\")\n    print(f\"Successfully completed: {completed}\")\n    print(f\"Failed: {failed}\")\n    print(f\"Success rate: {(completed/total_videos)*100:.1f}%\")\n    \n    if completed > 0:\n        avg_time = sum(r.get(\"processing_time_minutes\", 0) \n                      for r in results.values() \n                      if r[\"status\"] == \"completed\") / completed\n        print(f\"Average processing time: {avg_time:.1f} minutes per video\")\n    \n    print(f\"\\nOutput directory: {config.OUTPUT_DIR}\")\n    print(f\"Total output files: {sum(len(list(d.glob('*'))) for d in config.OUTPUT_DIR.iterdir() if d.is_dir())}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸš€ Download Results (Kaggle)\n\nIf you're running on Kaggle, this will prepare your results for download.","metadata":{}},{"cell_type":"code","source":"# Create downloadable archive of results\nimport zipfile\nimport shutil\n\ndef create_results_archive():\n    \"\"\"Create a zip archive of all results\"\"\"\n    if not config.OUTPUT_DIR.exists():\n        print(\"No output directory found\")\n        return None\n    \n    archive_path = config.WORKING_DIR / \"dubbing_results.zip\"\n    \n    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Add all files from output directory\n        for root, dirs, files in os.walk(config.OUTPUT_DIR):\n            for file in files:\n                file_path = Path(root) / file\n                arc_path = file_path.relative_to(config.OUTPUT_DIR)\n                zipf.write(file_path, arc_path)\n        \n        # Add processing results\n        results_file = config.OUTPUT_DIR / \"processing_results.json\"\n        if results_file.exists():\n            zipf.write(results_file, \"processing_results.json\")\n        \n        # Add logs\n        log_files = list(config.LOGS_DIR.glob(\"*.log\"))\n        for log_file in log_files:\n            zipf.write(log_file, f\"logs/{log_file.name}\")\n    \n    size_mb = archive_path.stat().st_size / (1024*1024)\n    print(f\"âœ“ Results archive created: {archive_path.name} ({size_mb:.1f}MB)\")\n    \n    return archive_path\n\nif IS_KAGGLE and config.OUTPUT_DIR.exists():\n    archive = create_results_archive()\n    if archive:\n        print(f\"\\nğŸ“¦ Download your results: {archive}\")\n        print(\"The archive contains:\")\n        print(\"- Dubbed videos (MP4)\")\n        print(\"- Subtitle files (SRT)\")\n        print(\"- Processing reports (JSON)\")\n        print(\"- Processing logs\")\nelse:\n    print(\"No results to archive\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“– Next Steps\n\n### What This Notebook Does:\n\n1. **âœ… Audio Processing**: Extracts and cleans audio from videos\n2. **âœ… Transcription**: Uses Whisper large-v3 to transcribe Arabic speech\n3. **âœ… Translation**: Translates Arabic to English/German using SeamlessM4T\n4. **âœ… Subtitles**: Generates properly formatted SRT subtitle files\n5. **âœ… Basic Video Assembly**: Creates videos with embedded subtitles\n\n### For Full Implementation:\n\nThe complete pipeline (as described in the project requirements) would include:\n\n- **Voice Cloning**: Using OpenVoice v2 to clone the original speaker's voice\n- **Speech Synthesis**: Generating dubbed audio in target languages\n- **Audio Synchronization**: Using DTW for precise timing alignment\n- **Quality Assurance**: Comprehensive audio/video quality checks\n- **Multi-track Assembly**: Creating videos with multiple audio tracks\n\n### Usage Tips:\n\n1. **Input Format**: Upload your Arabic video files to the Kaggle dataset\n2. **File Size**: Maximum 8GB per video file\n3. **Processing Time**: ~30-60 minutes per hour of video content\n4. **Memory Management**: The notebook automatically manages GPU memory\n5. **Checkpointing**: Processing can resume from interruptions\n\n### Output Files:\n\n- `{video_name}_en.srt` - English subtitles\n- `{video_name}_de.srt` - German subtitles  \n- `{video_name}_en_1080p.mp4` - English video with subtitles\n- `{video_name}_de_1080p.mp4` - German video with subtitles\n- `processing_results.json` - Processing summary and statistics\n\n### Customization:\n\nYou can modify the `config.py` file to:\n- Change target languages\n- Adjust quality settings\n- Modify processing parameters\n- Set custom output formats","metadata":{}},{"cell_type":"markdown","source":"## ğŸ§ª Environment Validation and Testing","metadata":{}},{"cell_type":"code","source":"# Download and create project files\nimport urllib.request\nimport shutil\n\n# Project files to create\nproject_files = {\n    'config.py': '''\"\"\"Configuration module for video dubbing automation\"\"\"\nimport os\nfrom pathlib import Path\n\nclass Config:\n    def __init__(self, local_mode=False):\n        if local_mode or not os.path.exists('/kaggle'):\n            self.BASE_DIR = Path.cwd()\n        else:\n            self.BASE_DIR = Path('/kaggle/working')\n        \n        # Directory structure\n        self.MODELS_DIR = self.BASE_DIR / 'models'\n        self.TEMP_DIR = self.BASE_DIR / 'temp'\n        self.OUTPUT_DIR = self.BASE_DIR / 'output'\n        self.LOGS_DIR = self.BASE_DIR / 'logs'\n        self.CHECKPOINTS_DIR = self.BASE_DIR / 'checkpoints'\n        \n        # Audio settings\n        self.AUDIO_SAMPLE_RATE = 48000\n        self.CHUNK_DURATION = 30  # seconds\n        \n        # Processing settings\n        self.TARGET_LANGUAGES = ['en', 'de']\n        self.BATCH_SIZE = 1\n        self.MAX_RETRIES = 3\n        \n        # Create directories\n        for directory in [self.MODELS_DIR, self.TEMP_DIR, self.OUTPUT_DIR, \n                         self.LOGS_DIR, self.CHECKPOINTS_DIR]:\n            directory.mkdir(parents=True, exist_ok=True)\n\nconfig = Config()''',\n    \n    'test_environment.py': '''# Environment validation will be created here''',\n    'demo_processor.py': '''# Demo processor will be created here'''\n}\n\n# Create the files\nfor filename, content in project_files.items():\n    with open(filename, 'w') as f:\n        f.write(content)\n    print(f\"âœ“ Created {filename}\")\n\nprint(\"\\nğŸ‰ Project files created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run environment validation\nprint(\"ğŸ” Running Environment Validation...\")\nprint(\"=\" * 50)\n\n# Import validation functions\ntry:\n    exec(open('test_environment.py').read())\n    validator = EnvironmentValidator(local_mode=not IS_KAGGLE)\n    validation_results = validator.run_full_validation()\n    \n    print(f\"\\nğŸ“Š Validation completed: {validation_results.get('overall_status', 'Unknown')}\")\n    \nexcept Exception as e:\n    print(f\"Validation failed: {e}\")\n    \n    # Manual basic checks\n    print(\"\\nğŸ”§ Running basic manual checks...\")\n    \n    # Check PyTorch and CUDA\n    try:\n        import torch\n        print(f\"âœ… PyTorch: {torch.__version__}\")\n        print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n        if torch.cuda.is_available():\n            print(f\"   Device: {torch.cuda.get_device_name()}\")\n    except ImportError:\n        print(\"âŒ PyTorch not available\")\n    \n    # Check other key packages\n    packages_to_check = ['transformers', 'whisper', 'librosa', 'moviepy']\n    for package in packages_to_check:\n        try:\n            __import__(package)\n            print(f\"âœ… {package}\")\n        except ImportError:\n            print(f\"âŒ {package} not installed\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ¬ Demo and Testing Mode\n\nBefore processing real videos, let's test the pipeline with synthetic data:","metadata":{}},{"cell_type":"code","source":"# Run demo pipeline test\nprint(\"ğŸ§ª Starting Demo Pipeline Test...\")\nprint(\"=\" * 50)\n\ntry:\n    # Create a simple demo processor\n    class SimpleDemoProcessor:\n        def __init__(self):\n            self.results = {}\n        \n        def test_audio_processing(self):\n            print(\"\\nğŸµ Testing Audio Processing...\")\n            try:\n                import librosa\n                import numpy as np\n                \n                # Create test audio\n                duration = 5  # seconds\n                sr = 22050\n                t = np.linspace(0, duration, duration * sr)\n                test_audio = 0.5 * np.sin(2 * np.pi * 440 * t)  # 440 Hz tone\n                \n                # Test librosa functionality\n                mfccs = librosa.feature.mfcc(y=test_audio, sr=sr, n_mfcc=13)\n                \n                print(\"  âœ… Audio generation: OK\")\n                print(\"  âœ… Librosa processing: OK\")\n                print(f\"  ğŸ“Š MFCC shape: {mfccs.shape}\")\n                \n                return {\"status\": \"âœ… PASSED\", \"details\": \"Audio processing working\"}\n            except Exception as e:\n                print(f\"  âŒ Audio processing failed: {e}\")\n                return {\"status\": \"âŒ FAILED\", \"error\": str(e)}\n        \n        def test_model_loading(self):\n            print(\"\\nğŸ¤– Testing Model Loading...\")\n            try:\n                import whisper\n                \n                # Test whisper model loading\n                print(\"  ğŸ“¥ Loading Whisper base model...\")\n                model = whisper.load_model(\"base\")\n                print(\"  âœ… Whisper model loaded successfully\")\n                \n                # Clean up\n                del model\n                \n                return {\"status\": \"âœ… PASSED\", \"details\": \"Model loading working\"}\n            except Exception as e:\n                print(f\"  âŒ Model loading failed: {e}\")\n                return {\"status\": \"âŒ FAILED\", \"error\": str(e)}\n        \n        def test_transformers(self):\n            print(\"\\nğŸŒ Testing Transformers...\")\n            try:\n                from transformers import pipeline\n                \n                # Test a simple pipeline\n                print(\"  ğŸ“¥ Creating translation pipeline...\")\n                # Use a small model for testing\n                translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ar-en\", \n                                     device=0 if torch.cuda.is_available() else -1)\n                \n                # Test translation\n                test_text = \"Ù…Ø±Ø­Ø¨Ø§\"  # \"Hello\" in Arabic\n                result = translator(test_text)\n                print(f\"  âœ… Translation test: '{test_text}' -> '{result[0]['translation_text']}'\")\n                \n                return {\"status\": \"âœ… PASSED\", \"details\": \"Translation working\"}\n            except Exception as e:\n                print(f\"  âŒ Translation test failed: {e}\")\n                return {\"status\": \"âš ï¸  PARTIAL\", \"error\": str(e)}\n        \n        def run_full_test(self):\n            print(\"ğŸš€ Running comprehensive demo test...\")\n            \n            tests = [\n                (\"audio_processing\", self.test_audio_processing),\n                (\"model_loading\", self.test_model_loading),\n                (\"transformers\", self.test_transformers)\n            ]\n            \n            results = {}\n            passed = 0\n            \n            for test_name, test_func in tests:\n                try:\n                    result = test_func()\n                    results[test_name] = result\n                    if \"âœ…\" in result[\"status\"]:\n                        passed += 1\n                except Exception as e:\n                    results[test_name] = {\"status\": \"âŒ FAILED\", \"error\": str(e)}\n            \n            print(f\"\\nğŸ“Š Demo Test Results: {passed}/{len(tests)} tests passed\")\n            \n            if passed == len(tests):\n                print(\"ğŸ‰ All tests passed! System ready for video processing.\")\n            elif passed >= len(tests) // 2:\n                print(\"âš ï¸  Some tests passed. System partially ready.\")\n            else:\n                print(\"âŒ Multiple tests failed. Please check installation.\")\n            \n            return results\n    \n    # Run the demo\n    demo = SimpleDemoProcessor()\n    demo_results = demo.run_full_test()\n    \nexcept Exception as e:\n    print(f\"Demo test failed: {e}\")\n    print(\"\\nğŸ“ Manual verification:\")\n    print(\"1. Check that all packages are installed\")\n    print(\"2. Verify GPU availability if needed\")\n    print(\"3. Ensure sufficient disk space (>20GB recommended)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ¥ Video Processing Pipeline\n\nOnce the environment validation passes, you can start processing your videos:","metadata":{}},{"cell_type":"code","source":"# Video processing configuration and setup\nprint(\"ğŸ¬ Video Dubbing Pipeline Configuration\")\nprint(\"=\" * 50)\n\n# Configuration settings\nVIDEO_CONFIG = {\n    \"source_language\": \"ar\",  # Arabic\n    \"target_languages\": [\"en\", \"de\"],  # English and German\n    \"quality_preset\": \"high\",  # high, medium, fast\n    \"enable_subtitles\": True,\n    \"enable_speaker_diarization\": True,\n    \"max_video_length_minutes\": 120,\n    \"chunk_size_minutes\": 30  # For memory management\n}\n\nprint(\"ğŸ“‹ Current Configuration:\")\nfor key, value in VIDEO_CONFIG.items():\n    print(f\"  {key}: {value}\")\n\n# Input validation\nprint(\"\\nğŸ“ Input Requirements:\")\nprint(\"  â€¢ Video format: MP4, AVI, MOV, MKV\")\nprint(\"  â€¢ Audio: Clear speech, minimal background noise\")\nprint(\"  â€¢ Language: Arabic (Egyptian dialect preferred)\")\nprint(\"  â€¢ Duration: 60-120 minutes recommended\")\nprint(\"  â€¢ Size: Up to 8GB per video\")\n\nprint(\"\\nğŸ¯ Expected Output:\")\nprint(\"  â€¢ English dubbed video (MP4)\")\nprint(\"  â€¢ German dubbed video (MP4)\")\nprint(\"  â€¢ Subtitle files (SRT/VTT)\")\nprint(\"  â€¢ Processing report (JSON)\")\nprint(\"  â€¢ Quality metrics and validation\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# File upload and processing initialization\nprint(\"ğŸ“¤ Video Upload and Processing\")\nprint(\"=\" * 50)\n\nif IS_KAGGLE:\n    print(\"ğŸ“ On Kaggle, your video files should be in:\")\n    print(\"   /kaggle/input/your-dataset-name/\")\n    print(\"\\nğŸ” Available input datasets:\")\n    \n    import os\n    input_path = Path('/kaggle/input')\n    if input_path.exists():\n        datasets = [d for d in input_path.iterdir() if d.is_dir()]\n        if datasets:\n            for dataset in datasets:\n                print(f\"   ğŸ“‚ {dataset.name}\")\n                # List video files in dataset\n                video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n                videos = [f for f in dataset.rglob('*') \n                         if f.suffix.lower() in video_extensions]\n                for video in videos[:3]:  # Show first 3 videos\n                    size_mb = video.stat().st_size / 1024**2\n                    print(f\"      ğŸ¥ {video.name} ({size_mb:.1f}MB)\")\n                if len(videos) > 3:\n                    print(f\"      ... and {len(videos)-3} more videos\")\n        else:\n            print(\"   âŒ No datasets found. Please upload your videos to a Kaggle dataset first.\")\n            print(\"\\nğŸ“– How to upload videos:\")\n            print(\"   1. Create a new dataset on Kaggle\")\n            print(\"   2. Upload your video files\")\n            print(\"   3. Add the dataset to this notebook\")\nelse:\n    print(\"ğŸ’» In local mode, place your videos in:\")\n    print(\"   ./input/ directory\")\n    \n    # Create input directory if it doesn't exist\n    input_dir = Path('./input')\n    input_dir.mkdir(exist_ok=True)\n    print(f\"   Created: {input_dir.absolute()}\")\n\nprint(\"\\nâš¡ Ready to start processing!\")\nprint(\"   Use the next cell to select and process videos.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}